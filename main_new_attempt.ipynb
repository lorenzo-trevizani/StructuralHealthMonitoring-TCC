{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy.fft import fft, ifft\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#IMPORTING FUNCTIONS FOR CLASSIFIERS\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedShuffleSplit, TimeSeriesSplit, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#IMPORTING FUNCTIONS FOR CLASSIFIERS METRICS\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#OPTMIZE PARAMETHERS\n",
    "import optuna\n",
    "\n",
    "#IMPORTING FUNCTIONS FROM ./defs\n",
    "\n",
    "from defs import defs_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_max_S1</th>\n",
       "      <th>s_sum_S1</th>\n",
       "      <th>s_mean_S1</th>\n",
       "      <th>s_std_S1</th>\n",
       "      <th>psd_max_S1</th>\n",
       "      <th>psd_sum_S1</th>\n",
       "      <th>psd_mean_S1</th>\n",
       "      <th>mean_S1</th>\n",
       "      <th>std_S1</th>\n",
       "      <th>median_S1</th>\n",
       "      <th>...</th>\n",
       "      <th>psd_max_S30</th>\n",
       "      <th>psd_sum_S30</th>\n",
       "      <th>psd_mean_S30</th>\n",
       "      <th>mean_S30</th>\n",
       "      <th>std_S30</th>\n",
       "      <th>median_S30</th>\n",
       "      <th>skew_S30</th>\n",
       "      <th>amp_max_min_S30</th>\n",
       "      <th>kurtosis_S30</th>\n",
       "      <th>Scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0017098931640625</td>\n",
       "      <td>0.514871739328125</td>\n",
       "      <td>0.0005037883946459149</td>\n",
       "      <td>0.00036465933472807325</td>\n",
       "      <td>1.4618673162538337e-06</td>\n",
       "      <td>0.00019764415943894105</td>\n",
       "      <td>1.9338958849211452e-07</td>\n",
       "      <td>-0.001357755576621094</td>\n",
       "      <td>0.14353815569284573</td>\n",
       "      <td>-0.0022832825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3941068882962035e-06</td>\n",
       "      <td>0.00019870183665858214</td>\n",
       "      <td>1.944244977089845e-07</td>\n",
       "      <td>-0.0009625774402050785</td>\n",
       "      <td>0.14051081616489033</td>\n",
       "      <td>-0.00160728</td>\n",
       "      <td>-0.028261960420297376</td>\n",
       "      <td>0.9763257999999999</td>\n",
       "      <td>0.3741716150735144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0037203177734375</td>\n",
       "      <td>2.49511725</td>\n",
       "      <td>0.0024414063111545987</td>\n",
       "      <td>0.00042207452952675517</td>\n",
       "      <td>6.920382167677479e-06</td>\n",
       "      <td>0.003136830570841197</td>\n",
       "      <td>3.0693058423103688e-06</td>\n",
       "      <td>-0.00040519520195312557</td>\n",
       "      <td>0.15993237175747657</td>\n",
       "      <td>0.0015726744000000002</td>\n",
       "      <td>...</td>\n",
       "      <td>6.195577443248768e-06</td>\n",
       "      <td>0.003116607907721954</td>\n",
       "      <td>3.0495185007064127e-06</td>\n",
       "      <td>-0.0007408178286132816</td>\n",
       "      <td>0.13220517439369525</td>\n",
       "      <td>0.0031077394999999997</td>\n",
       "      <td>-0.13960095714872756</td>\n",
       "      <td>0.8766658</td>\n",
       "      <td>-0.19597598823181217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00551249375</td>\n",
       "      <td>4.491211</td>\n",
       "      <td>0.004394531311154599</td>\n",
       "      <td>0.00041604672746616624</td>\n",
       "      <td>1.5193793671894531e-05</td>\n",
       "      <td>0.00995683516564242</td>\n",
       "      <td>9.742500162076733e-06</td>\n",
       "      <td>0.0023152742476074215</td>\n",
       "      <td>0.17714985774876585</td>\n",
       "      <td>0.002926843</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5196755704974384e-05</td>\n",
       "      <td>0.009943901685402065</td>\n",
       "      <td>9.7298450933484e-06</td>\n",
       "      <td>-0.0010596247472656256</td>\n",
       "      <td>0.14178383623011304</td>\n",
       "      <td>-0.003839492</td>\n",
       "      <td>0.15268936763001495</td>\n",
       "      <td>0.8964205000000001</td>\n",
       "      <td>0.019830716117583247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0080443560546875</td>\n",
       "      <td>6.48730475</td>\n",
       "      <td>0.006347656311154599</td>\n",
       "      <td>0.0005073348621225908</td>\n",
       "      <td>3.2355832167293724e-05</td>\n",
       "      <td>0.0207211160758084</td>\n",
       "      <td>2.0275064653432874e-05</td>\n",
       "      <td>0.002870112068554689</td>\n",
       "      <td>0.22139169075801352</td>\n",
       "      <td>0.0073151234999999995</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0252831934927443e-05</td>\n",
       "      <td>0.020688838629808217</td>\n",
       "      <td>2.024348202525266e-05</td>\n",
       "      <td>-0.0006096456118164065</td>\n",
       "      <td>0.16496941710744412</td>\n",
       "      <td>-0.0008257963500000001</td>\n",
       "      <td>-0.03433807485017546</td>\n",
       "      <td>1.0781062000000001</td>\n",
       "      <td>-0.09253528403808797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0097765474609375</td>\n",
       "      <td>8.4833985</td>\n",
       "      <td>0.008300781311154599</td>\n",
       "      <td>0.0004901323388503907</td>\n",
       "      <td>4.779044012798174e-05</td>\n",
       "      <td>0.035332175243537406</td>\n",
       "      <td>3.45716000426002e-05</td>\n",
       "      <td>0.0012931235627929687</td>\n",
       "      <td>0.1835278711827127</td>\n",
       "      <td>0.0063275250000000005</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4295721381761545e-05</td>\n",
       "      <td>0.03529177519580718</td>\n",
       "      <td>3.453206966321642e-05</td>\n",
       "      <td>-0.0008355930417968758</td>\n",
       "      <td>0.1391090713471743</td>\n",
       "      <td>0.005240619</td>\n",
       "      <td>-0.10385369203581078</td>\n",
       "      <td>1.0376701</td>\n",
       "      <td>0.058457058525502426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>0.4920778080078125</td>\n",
       "      <td>501.51855625</td>\n",
       "      <td>0.490722657778865</td>\n",
       "      <td>0.00046458126034279115</td>\n",
       "      <td>0.12107028456688677</td>\n",
       "      <td>123.05336971627655</td>\n",
       "      <td>0.12040447134665025</td>\n",
       "      <td>0.00476826078776367</td>\n",
       "      <td>0.1802345355376812</td>\n",
       "      <td>0.002092819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12101891305769145</td>\n",
       "      <td>123.05334544891326</td>\n",
       "      <td>0.12040444760167639</td>\n",
       "      <td>0.0022268341846679663</td>\n",
       "      <td>0.1463088548130687</td>\n",
       "      <td>0.004260801</td>\n",
       "      <td>-0.06072306121432907</td>\n",
       "      <td>0.9396711</td>\n",
       "      <td>-0.07285194834540976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>0.4938183634765625</td>\n",
       "      <td>503.51464999999996</td>\n",
       "      <td>0.4926757827788649</td>\n",
       "      <td>0.00043057361012635695</td>\n",
       "      <td>0.1219282880533352</td>\n",
       "      <td>124.03483190083494</td>\n",
       "      <td>0.12136480616520054</td>\n",
       "      <td>0.005682367039843752</td>\n",
       "      <td>0.17372629503298528</td>\n",
       "      <td>0.0048936195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12188481440507852</td>\n",
       "      <td>124.03481609411834</td>\n",
       "      <td>0.12136479069874594</td>\n",
       "      <td>0.0016730884660156261</td>\n",
       "      <td>0.1432019711880003</td>\n",
       "      <td>0.009320239000000001</td>\n",
       "      <td>-0.0628559234161243</td>\n",
       "      <td>1.0328667</td>\n",
       "      <td>0.23811567861600835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>0.49584270625</td>\n",
       "      <td>505.51074375</td>\n",
       "      <td>0.494628907778865</td>\n",
       "      <td>0.0004405659615977529</td>\n",
       "      <td>0.12292999467066189</td>\n",
       "      <td>125.02021271003738</td>\n",
       "      <td>0.12232897525443971</td>\n",
       "      <td>0.004501759137304686</td>\n",
       "      <td>0.17917499437740247</td>\n",
       "      <td>0.0007907776000000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12288674559306505</td>\n",
       "      <td>125.02020344456297</td>\n",
       "      <td>0.12232896618841778</td>\n",
       "      <td>0.001823433908984375</td>\n",
       "      <td>0.15540852807998115</td>\n",
       "      <td>0.005102217500000001</td>\n",
       "      <td>0.12789408137547786</td>\n",
       "      <td>1.0024451</td>\n",
       "      <td>-0.11665106960237459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>0.49819061132812503</td>\n",
       "      <td>507.5068375</td>\n",
       "      <td>0.496582032778865</td>\n",
       "      <td>0.0004507211880661849</td>\n",
       "      <td>0.12409694260774547</td>\n",
       "      <td>126.00949231690171</td>\n",
       "      <td>0.12329695921418954</td>\n",
       "      <td>0.005475126960449214</td>\n",
       "      <td>0.18346295749577451</td>\n",
       "      <td>0.0024689250000000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12384325138224284</td>\n",
       "      <td>126.00946776695636</td>\n",
       "      <td>0.1232969351927166</td>\n",
       "      <td>0.001275242775927735</td>\n",
       "      <td>0.1362552667126023</td>\n",
       "      <td>-5.1783374999999994e-05</td>\n",
       "      <td>0.02412409924378543</td>\n",
       "      <td>0.8374804</td>\n",
       "      <td>-0.05377166902358077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>0.49997731875</td>\n",
       "      <td>509.50293125</td>\n",
       "      <td>0.498535157778865</td>\n",
       "      <td>0.0004294737572556393</td>\n",
       "      <td>0.12498865963221956</td>\n",
       "      <td>127.00265636253536</td>\n",
       "      <td>0.124268743994653</td>\n",
       "      <td>0.006585605099121103</td>\n",
       "      <td>0.1626818627883961</td>\n",
       "      <td>0.0087072235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12493877742011993</td>\n",
       "      <td>127.00264407684705</td>\n",
       "      <td>0.12426873197343155</td>\n",
       "      <td>0.0015054804335937497</td>\n",
       "      <td>0.14042663692454596</td>\n",
       "      <td>0.0006542024</td>\n",
       "      <td>0.03090294705324049</td>\n",
       "      <td>0.9314082</td>\n",
       "      <td>0.004002674910329684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7936 rows × 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 s_max_S1            s_sum_S1              s_mean_S1  \\\n",
       "0      0.0017098931640625   0.514871739328125  0.0005037883946459149   \n",
       "1      0.0037203177734375          2.49511725  0.0024414063111545987   \n",
       "2           0.00551249375            4.491211   0.004394531311154599   \n",
       "3      0.0080443560546875          6.48730475   0.006347656311154599   \n",
       "4      0.0097765474609375           8.4833985   0.008300781311154599   \n",
       "...                   ...                 ...                    ...   \n",
       "7931   0.4920778080078125        501.51855625      0.490722657778865   \n",
       "7932   0.4938183634765625  503.51464999999996     0.4926757827788649   \n",
       "7933        0.49584270625        505.51074375      0.494628907778865   \n",
       "7934  0.49819061132812503         507.5068375      0.496582032778865   \n",
       "7935        0.49997731875        509.50293125      0.498535157778865   \n",
       "\n",
       "                    s_std_S1              psd_max_S1              psd_sum_S1  \\\n",
       "0     0.00036465933472807325  1.4618673162538337e-06  0.00019764415943894105   \n",
       "1     0.00042207452952675517   6.920382167677479e-06    0.003136830570841197   \n",
       "2     0.00041604672746616624  1.5193793671894531e-05     0.00995683516564242   \n",
       "3      0.0005073348621225908  3.2355832167293724e-05      0.0207211160758084   \n",
       "4      0.0004901323388503907   4.779044012798174e-05    0.035332175243537406   \n",
       "...                      ...                     ...                     ...   \n",
       "7931  0.00046458126034279115     0.12107028456688677      123.05336971627655   \n",
       "7932  0.00043057361012635695      0.1219282880533352      124.03483190083494   \n",
       "7933   0.0004405659615977529     0.12292999467066189      125.02021271003738   \n",
       "7934   0.0004507211880661849     0.12409694260774547      126.00949231690171   \n",
       "7935   0.0004294737572556393     0.12498865963221956      127.00265636253536   \n",
       "\n",
       "                 psd_mean_S1                  mean_S1               std_S1  \\\n",
       "0     1.9338958849211452e-07    -0.001357755576621094  0.14353815569284573   \n",
       "1     3.0693058423103688e-06  -0.00040519520195312557  0.15993237175747657   \n",
       "2      9.742500162076733e-06    0.0023152742476074215  0.17714985774876585   \n",
       "3     2.0275064653432874e-05     0.002870112068554689  0.22139169075801352   \n",
       "4       3.45716000426002e-05    0.0012931235627929687   0.1835278711827127   \n",
       "...                      ...                      ...                  ...   \n",
       "7931     0.12040447134665025      0.00476826078776367   0.1802345355376812   \n",
       "7932     0.12136480616520054     0.005682367039843752  0.17372629503298528   \n",
       "7933     0.12232897525443971     0.004501759137304686  0.17917499437740247   \n",
       "7934     0.12329695921418954     0.005475126960449214  0.18346295749577451   \n",
       "7935       0.124268743994653     0.006585605099121103   0.1626818627883961   \n",
       "\n",
       "                  median_S1  ...             psd_max_S30  \\\n",
       "0             -0.0022832825  ...  1.3941068882962035e-06   \n",
       "1     0.0015726744000000002  ...   6.195577443248768e-06   \n",
       "2               0.002926843  ...  1.5196755704974384e-05   \n",
       "3     0.0073151234999999995  ...  3.0252831934927443e-05   \n",
       "4     0.0063275250000000005  ...  4.4295721381761545e-05   \n",
       "...                     ...  ...                     ...   \n",
       "7931            0.002092819  ...     0.12101891305769145   \n",
       "7932           0.0048936195  ...     0.12188481440507852   \n",
       "7933  0.0007907776000000001  ...     0.12288674559306505   \n",
       "7934  0.0024689250000000003  ...     0.12384325138224284   \n",
       "7935           0.0087072235  ...     0.12493877742011993   \n",
       "\n",
       "                 psd_sum_S30            psd_mean_S30                mean_S30  \\\n",
       "0     0.00019870183665858214   1.944244977089845e-07  -0.0009625774402050785   \n",
       "1       0.003116607907721954  3.0495185007064127e-06  -0.0007408178286132816   \n",
       "2       0.009943901685402065     9.7298450933484e-06  -0.0010596247472656256   \n",
       "3       0.020688838629808217   2.024348202525266e-05  -0.0006096456118164065   \n",
       "4        0.03529177519580718   3.453206966321642e-05  -0.0008355930417968758   \n",
       "...                      ...                     ...                     ...   \n",
       "7931      123.05334544891326     0.12040444760167639   0.0022268341846679663   \n",
       "7932      124.03481609411834     0.12136479069874594   0.0016730884660156261   \n",
       "7933      125.02020344456297     0.12232896618841778    0.001823433908984375   \n",
       "7934      126.00946776695636      0.1232969351927166    0.001275242775927735   \n",
       "7935      127.00264407684705     0.12426873197343155   0.0015054804335937497   \n",
       "\n",
       "                  std_S30               median_S30               skew_S30  \\\n",
       "0     0.14051081616489033              -0.00160728  -0.028261960420297376   \n",
       "1     0.13220517439369525    0.0031077394999999997   -0.13960095714872756   \n",
       "2     0.14178383623011304             -0.003839492    0.15268936763001495   \n",
       "3     0.16496941710744412   -0.0008257963500000001   -0.03433807485017546   \n",
       "4      0.1391090713471743              0.005240619   -0.10385369203581078   \n",
       "...                   ...                      ...                    ...   \n",
       "7931   0.1463088548130687              0.004260801   -0.06072306121432907   \n",
       "7932   0.1432019711880003     0.009320239000000001    -0.0628559234161243   \n",
       "7933  0.15540852807998115     0.005102217500000001    0.12789408137547786   \n",
       "7934   0.1362552667126023  -5.1783374999999994e-05    0.02412409924378543   \n",
       "7935  0.14042663692454596             0.0006542024    0.03090294705324049   \n",
       "\n",
       "         amp_max_min_S30          kurtosis_S30 Scenario  \n",
       "0     0.9763257999999999    0.3741716150735144        1  \n",
       "1              0.8766658  -0.19597598823181217        1  \n",
       "2     0.8964205000000001  0.019830716117583247        1  \n",
       "3     1.0781062000000001  -0.09253528403808797        1  \n",
       "4              1.0376701  0.058457058525502426        1  \n",
       "...                  ...                   ...      ...  \n",
       "7931           0.9396711  -0.07285194834540976        0  \n",
       "7932           1.0328667   0.23811567861600835        0  \n",
       "7933           1.0024451  -0.11665106960237459        0  \n",
       "7934           0.8374804  -0.05377166902358077        0  \n",
       "7935           0.9314082  0.004002674910329684        0  \n",
       "\n",
       "[7936 rows x 391 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = 1024;\n",
    "\n",
    "df_final = pd.read_csv('df_csv/' + str(samples) + '_samples/dataframe_final', index_col=0, dtype='unicode');\n",
    "df_quick_test = pd.read_csv('df_csv/' + str(samples) + '_samples/dataframe_simples', index_col=0, dtype='unicode');\n",
    "df_finalB = pd.read_csv('df_csv/' + str(samples) + '_samples/dataframeB_final', index_col=0, dtype='unicode');\n",
    "\n",
    "df_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando dataframe voltada para 1 sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_max_S1</th>\n",
       "      <th>s_sum_S1</th>\n",
       "      <th>s_mean_S1</th>\n",
       "      <th>s_std_S1</th>\n",
       "      <th>psd_max_S1</th>\n",
       "      <th>psd_sum_S1</th>\n",
       "      <th>psd_mean_S1</th>\n",
       "      <th>mean_S1</th>\n",
       "      <th>std_S1</th>\n",
       "      <th>median_S1</th>\n",
       "      <th>skew_S1</th>\n",
       "      <th>amp_max_min_S1</th>\n",
       "      <th>kurtosis_S1</th>\n",
       "      <th>damaged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0017098931640625</td>\n",
       "      <td>0.514871739328125</td>\n",
       "      <td>0.0005037883946459149</td>\n",
       "      <td>0.00036465933472807325</td>\n",
       "      <td>1.4618673162538337e-06</td>\n",
       "      <td>0.00019764415943894105</td>\n",
       "      <td>1.9338958849211452e-07</td>\n",
       "      <td>-0.001357755576621094</td>\n",
       "      <td>0.14353815569284573</td>\n",
       "      <td>-0.0022832825</td>\n",
       "      <td>0.01540848754149542</td>\n",
       "      <td>0.9939469999999999</td>\n",
       "      <td>0.10365608906656476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0037203177734375</td>\n",
       "      <td>2.49511725</td>\n",
       "      <td>0.0024414063111545987</td>\n",
       "      <td>0.00042207452952675517</td>\n",
       "      <td>6.920382167677479e-06</td>\n",
       "      <td>0.003136830570841197</td>\n",
       "      <td>3.0693058423103688e-06</td>\n",
       "      <td>-0.00040519520195312557</td>\n",
       "      <td>0.15993237175747657</td>\n",
       "      <td>0.0015726744000000002</td>\n",
       "      <td>-0.03158462525774426</td>\n",
       "      <td>0.9305502</td>\n",
       "      <td>-0.10123098978136014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00551249375</td>\n",
       "      <td>4.491211</td>\n",
       "      <td>0.004394531311154599</td>\n",
       "      <td>0.00041604672746616624</td>\n",
       "      <td>1.5193793671894531e-05</td>\n",
       "      <td>0.00995683516564242</td>\n",
       "      <td>9.742500162076733e-06</td>\n",
       "      <td>0.0023152742476074215</td>\n",
       "      <td>0.17714985774876585</td>\n",
       "      <td>0.002926843</td>\n",
       "      <td>-0.003200578863888679</td>\n",
       "      <td>1.3379102999999999</td>\n",
       "      <td>0.4780702410549287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0080443560546875</td>\n",
       "      <td>6.48730475</td>\n",
       "      <td>0.006347656311154599</td>\n",
       "      <td>0.0005073348621225908</td>\n",
       "      <td>3.2355832167293724e-05</td>\n",
       "      <td>0.0207211160758084</td>\n",
       "      <td>2.0275064653432874e-05</td>\n",
       "      <td>0.002870112068554689</td>\n",
       "      <td>0.22139169075801352</td>\n",
       "      <td>0.0073151234999999995</td>\n",
       "      <td>0.04559151014305592</td>\n",
       "      <td>1.3072631000000001</td>\n",
       "      <td>-0.3619600938367933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0097765474609375</td>\n",
       "      <td>8.4833985</td>\n",
       "      <td>0.008300781311154599</td>\n",
       "      <td>0.0004901323388503907</td>\n",
       "      <td>4.779044012798174e-05</td>\n",
       "      <td>0.035332175243537406</td>\n",
       "      <td>3.45716000426002e-05</td>\n",
       "      <td>0.0012931235627929687</td>\n",
       "      <td>0.1835278711827127</td>\n",
       "      <td>0.0063275250000000005</td>\n",
       "      <td>-0.13343487673558488</td>\n",
       "      <td>1.341857</td>\n",
       "      <td>0.33859537447306876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.009541761328125</td>\n",
       "      <td>8.4833985</td>\n",
       "      <td>0.008300781311154599</td>\n",
       "      <td>0.0004209658098521952</td>\n",
       "      <td>4.552260462145088e-05</td>\n",
       "      <td>0.035299973302814446</td>\n",
       "      <td>3.454009129433899e-05</td>\n",
       "      <td>-0.008528785652050773</td>\n",
       "      <td>0.1629409560350122</td>\n",
       "      <td>-0.00871709</td>\n",
       "      <td>0.04050250389091984</td>\n",
       "      <td>0.9905214</td>\n",
       "      <td>-0.1337553170367305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.07181730136718749</td>\n",
       "      <td>72.35839874999999</td>\n",
       "      <td>0.07080078155577299</td>\n",
       "      <td>0.00039536393454544876</td>\n",
       "      <td>0.002578862387832715</td>\n",
       "      <td>2.5615954675715518</td>\n",
       "      <td>0.0025064534907745127</td>\n",
       "      <td>-0.0005630072265624996</td>\n",
       "      <td>0.16909837407343115</td>\n",
       "      <td>0.0028338525</td>\n",
       "      <td>-0.013307286768657136</td>\n",
       "      <td>1.0586799</td>\n",
       "      <td>-0.17523202302588414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.1248385904296875</td>\n",
       "      <td>126.25293</td>\n",
       "      <td>0.123535156555773</td>\n",
       "      <td>0.00045071825453314154</td>\n",
       "      <td>0.007792336830235631</td>\n",
       "      <td>7.798441544676404</td>\n",
       "      <td>0.007630569026102156</td>\n",
       "      <td>0.0021597689768945334</td>\n",
       "      <td>0.18104641285732015</td>\n",
       "      <td>-0.001231946</td>\n",
       "      <td>0.043989059343233515</td>\n",
       "      <td>1.1408564</td>\n",
       "      <td>-0.10399815661794598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.1190133853515625</td>\n",
       "      <td>120.26464874999999</td>\n",
       "      <td>0.11767578155577299</td>\n",
       "      <td>0.0004006329310843574</td>\n",
       "      <td>0.007082092946419756</td>\n",
       "      <td>7.076200286540319</td>\n",
       "      <td>0.006923875035753736</td>\n",
       "      <td>3.7345056347656036e-05</td>\n",
       "      <td>0.16184869514077863</td>\n",
       "      <td>0.0014814165</td>\n",
       "      <td>-0.057627646433395095</td>\n",
       "      <td>1.0972811999999998</td>\n",
       "      <td>0.12819952663646905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.138317541015625</td>\n",
       "      <td>140.22558625</td>\n",
       "      <td>0.137207031555773</td>\n",
       "      <td>0.0004003864404333362</td>\n",
       "      <td>0.009565871076304551</td>\n",
       "      <td>9.620050136818419</td>\n",
       "      <td>0.009412964908824284</td>\n",
       "      <td>-0.0012100230635742183</td>\n",
       "      <td>0.14477194441903124</td>\n",
       "      <td>-0.004046116</td>\n",
       "      <td>0.07917750019047609</td>\n",
       "      <td>1.0238944</td>\n",
       "      <td>0.03400779530213072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                s_max_S1            s_sum_S1              s_mean_S1  \\\n",
       "0     0.0017098931640625   0.514871739328125  0.0005037883946459149   \n",
       "1     0.0037203177734375          2.49511725  0.0024414063111545987   \n",
       "2          0.00551249375            4.491211   0.004394531311154599   \n",
       "3     0.0080443560546875          6.48730475   0.006347656311154599   \n",
       "4     0.0097765474609375           8.4833985   0.008300781311154599   \n",
       "..                   ...                 ...                    ...   \n",
       "507    0.009541761328125           8.4833985   0.008300781311154599   \n",
       "508  0.07181730136718749   72.35839874999999    0.07080078155577299   \n",
       "509   0.1248385904296875           126.25293      0.123535156555773   \n",
       "510   0.1190133853515625  120.26464874999999    0.11767578155577299   \n",
       "511    0.138317541015625        140.22558625      0.137207031555773   \n",
       "\n",
       "                   s_std_S1              psd_max_S1              psd_sum_S1  \\\n",
       "0    0.00036465933472807325  1.4618673162538337e-06  0.00019764415943894105   \n",
       "1    0.00042207452952675517   6.920382167677479e-06    0.003136830570841197   \n",
       "2    0.00041604672746616624  1.5193793671894531e-05     0.00995683516564242   \n",
       "3     0.0005073348621225908  3.2355832167293724e-05      0.0207211160758084   \n",
       "4     0.0004901323388503907   4.779044012798174e-05    0.035332175243537406   \n",
       "..                      ...                     ...                     ...   \n",
       "507   0.0004209658098521952   4.552260462145088e-05    0.035299973302814446   \n",
       "508  0.00039536393454544876    0.002578862387832715      2.5615954675715518   \n",
       "509  0.00045071825453314154    0.007792336830235631       7.798441544676404   \n",
       "510   0.0004006329310843574    0.007082092946419756       7.076200286540319   \n",
       "511   0.0004003864404333362    0.009565871076304551       9.620050136818419   \n",
       "\n",
       "                psd_mean_S1                  mean_S1               std_S1  \\\n",
       "0    1.9338958849211452e-07    -0.001357755576621094  0.14353815569284573   \n",
       "1    3.0693058423103688e-06  -0.00040519520195312557  0.15993237175747657   \n",
       "2     9.742500162076733e-06    0.0023152742476074215  0.17714985774876585   \n",
       "3    2.0275064653432874e-05     0.002870112068554689  0.22139169075801352   \n",
       "4      3.45716000426002e-05    0.0012931235627929687   0.1835278711827127   \n",
       "..                      ...                      ...                  ...   \n",
       "507   3.454009129433899e-05    -0.008528785652050773   0.1629409560350122   \n",
       "508   0.0025064534907745127   -0.0005630072265624996  0.16909837407343115   \n",
       "509    0.007630569026102156    0.0021597689768945334  0.18104641285732015   \n",
       "510    0.006923875035753736   3.7345056347656036e-05  0.16184869514077863   \n",
       "511    0.009412964908824284   -0.0012100230635742183  0.14477194441903124   \n",
       "\n",
       "                 median_S1                skew_S1      amp_max_min_S1  \\\n",
       "0            -0.0022832825    0.01540848754149542  0.9939469999999999   \n",
       "1    0.0015726744000000002   -0.03158462525774426           0.9305502   \n",
       "2              0.002926843  -0.003200578863888679  1.3379102999999999   \n",
       "3    0.0073151234999999995    0.04559151014305592  1.3072631000000001   \n",
       "4    0.0063275250000000005   -0.13343487673558488            1.341857   \n",
       "..                     ...                    ...                 ...   \n",
       "507            -0.00871709    0.04050250389091984           0.9905214   \n",
       "508           0.0028338525  -0.013307286768657136           1.0586799   \n",
       "509           -0.001231946   0.043989059343233515           1.1408564   \n",
       "510           0.0014814165  -0.057627646433395095  1.0972811999999998   \n",
       "511           -0.004046116    0.07917750019047609           1.0238944   \n",
       "\n",
       "              kurtosis_S1  damaged  \n",
       "0     0.10365608906656476        1  \n",
       "1    -0.10123098978136014        1  \n",
       "2      0.4780702410549287        1  \n",
       "3     -0.3619600938367933        1  \n",
       "4     0.33859537447306876        1  \n",
       "..                    ...      ...  \n",
       "507   -0.1337553170367305        0  \n",
       "508  -0.17523202302588414        0  \n",
       "509  -0.10399815661794598        0  \n",
       "510   0.12819952663646905        0  \n",
       "511   0.03400779530213072        0  \n",
       "\n",
       "[512 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ready = defs_.createScaledDataframeScenario(df_final, 1);\n",
    "df_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check values from database's target \n",
    "plt.figure()\n",
    "plt.title(\"Representatividade da variável target no dataframe\");\n",
    "plt.xlabel('Valor');\n",
    "plt.ylabel('Quantidade');\n",
    "\n",
    "plt.hist(df_ready['damaged'].astype(int),bins = 50,color='purple');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_max_S1</th>\n",
       "      <th>s_sum_S1</th>\n",
       "      <th>s_mean_S1</th>\n",
       "      <th>s_std_S1</th>\n",
       "      <th>psd_max_S1</th>\n",
       "      <th>psd_sum_S1</th>\n",
       "      <th>psd_mean_S1</th>\n",
       "      <th>mean_S1</th>\n",
       "      <th>std_S1</th>\n",
       "      <th>median_S1</th>\n",
       "      <th>skew_S1</th>\n",
       "      <th>amp_max_min_S1</th>\n",
       "      <th>kurtosis_S1</th>\n",
       "      <th>damaged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001700947265625</td>\n",
       "      <td>0.5254187902617188</td>\n",
       "      <td>0.0005141084053441476</td>\n",
       "      <td>0.000375134111546019</td>\n",
       "      <td>1.4466108002185822e-06</td>\n",
       "      <td>0.0002069718906404618</td>\n",
       "      <td>2.0251652704546163e-07</td>\n",
       "      <td>-0.0012994515618164058</td>\n",
       "      <td>0.16106936861370183</td>\n",
       "      <td>0.0056914465</td>\n",
       "      <td>-0.11066721150373085</td>\n",
       "      <td>0.9869401</td>\n",
       "      <td>-0.09655415028892422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0036015025390625</td>\n",
       "      <td>2.49511725</td>\n",
       "      <td>0.0024414063111545987</td>\n",
       "      <td>0.00041312351519890973</td>\n",
       "      <td>6.485410269436816e-06</td>\n",
       "      <td>0.0031330104014424187</td>\n",
       "      <td>3.065567907477905e-06</td>\n",
       "      <td>-0.0011206226858398436</td>\n",
       "      <td>0.16205377336559978</td>\n",
       "      <td>-0.005452681</td>\n",
       "      <td>0.0944179297661639</td>\n",
       "      <td>1.1304659</td>\n",
       "      <td>-0.05224544083007343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0061169798828125</td>\n",
       "      <td>4.491211</td>\n",
       "      <td>0.004394531311154599</td>\n",
       "      <td>0.0004915720549679346</td>\n",
       "      <td>1.8708721443366413e-05</td>\n",
       "      <td>0.009991863298801156</td>\n",
       "      <td>9.776774264971777e-06</td>\n",
       "      <td>-0.00013747753720703043</td>\n",
       "      <td>0.21131295994117938</td>\n",
       "      <td>-0.009470138999999999</td>\n",
       "      <td>0.14395121532071178</td>\n",
       "      <td>1.3191813</td>\n",
       "      <td>-0.02537046544895416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00766963984375</td>\n",
       "      <td>6.48730475</td>\n",
       "      <td>0.006347656311154599</td>\n",
       "      <td>0.0004465030141622532</td>\n",
       "      <td>2.9411687666418763e-05</td>\n",
       "      <td>0.02069146595454656</td>\n",
       "      <td>2.0246052793098393e-05</td>\n",
       "      <td>0.0017813727404296863</td>\n",
       "      <td>0.1838244512744018</td>\n",
       "      <td>0.00034578705</td>\n",
       "      <td>0.046062480131920824</td>\n",
       "      <td>1.3538154</td>\n",
       "      <td>0.057745819304428014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009855110351562502</td>\n",
       "      <td>8.4833985</td>\n",
       "      <td>0.008300781311154599</td>\n",
       "      <td>0.0004174833604398379</td>\n",
       "      <td>4.856160002073719e-05</td>\n",
       "      <td>0.03529848125597924</td>\n",
       "      <td>3.4538631365928804e-05</td>\n",
       "      <td>0.0015248213455078107</td>\n",
       "      <td>0.17145975380650394</td>\n",
       "      <td>0.0046324915000000005</td>\n",
       "      <td>-0.023202447658407736</td>\n",
       "      <td>1.1826402</td>\n",
       "      <td>0.07612509751908325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>0.49239281035156246</td>\n",
       "      <td>501.51855625</td>\n",
       "      <td>0.490722657778865</td>\n",
       "      <td>0.00044506303697406735</td>\n",
       "      <td>0.12122533984295487</td>\n",
       "      <td>123.05336064365521</td>\n",
       "      <td>0.12040446246932995</td>\n",
       "      <td>-0.005335176022753905</td>\n",
       "      <td>0.17912190645622933</td>\n",
       "      <td>-0.002185503</td>\n",
       "      <td>-0.027338265936375988</td>\n",
       "      <td>1.2201605</td>\n",
       "      <td>0.1292269205289478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>0.493883707421875</td>\n",
       "      <td>503.51464999999996</td>\n",
       "      <td>0.4926757827788649</td>\n",
       "      <td>0.00046532519379978156</td>\n",
       "      <td>0.12196055822838811</td>\n",
       "      <td>124.03484781025901</td>\n",
       "      <td>0.12136482173215167</td>\n",
       "      <td>-0.004272731928710935</td>\n",
       "      <td>0.18660141904175448</td>\n",
       "      <td>-0.004680157</td>\n",
       "      <td>0.02906129705454456</td>\n",
       "      <td>1.2731080000000001</td>\n",
       "      <td>0.017920414778662686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>0.4961542658203125</td>\n",
       "      <td>505.51074374999996</td>\n",
       "      <td>0.4946289077788649</td>\n",
       "      <td>0.0004525283678130062</td>\n",
       "      <td>0.12308452774584668</td>\n",
       "      <td>125.0202181693351</td>\n",
       "      <td>0.12232898059621829</td>\n",
       "      <td>-0.0033993002719726567</td>\n",
       "      <td>0.17105023591780796</td>\n",
       "      <td>-0.0072027485</td>\n",
       "      <td>0.07841541616346018</td>\n",
       "      <td>1.1024421000000002</td>\n",
       "      <td>-0.11029827526708935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>0.4978674255859375</td>\n",
       "      <td>507.50683749999996</td>\n",
       "      <td>0.4965820327788649</td>\n",
       "      <td>0.00041276876722514424</td>\n",
       "      <td>0.12393598672978451</td>\n",
       "      <td>126.00947557064775</td>\n",
       "      <td>0.12329694282842246</td>\n",
       "      <td>-0.0003443699025390616</td>\n",
       "      <td>0.15291595087602328</td>\n",
       "      <td>0.0010140499</td>\n",
       "      <td>0.06107307952190012</td>\n",
       "      <td>0.8754583</td>\n",
       "      <td>-0.22758344886867787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>0.49994597695312504</td>\n",
       "      <td>509.50293124999996</td>\n",
       "      <td>0.4985351577788649</td>\n",
       "      <td>0.00045454396601254764</td>\n",
       "      <td>0.12497298993580731</td>\n",
       "      <td>127.00266768757737</td>\n",
       "      <td>0.12426875507590741</td>\n",
       "      <td>-0.0003093641684472658</td>\n",
       "      <td>0.1670772703780503</td>\n",
       "      <td>-0.0054839625</td>\n",
       "      <td>0.060145534529472605</td>\n",
       "      <td>1.0216575</td>\n",
       "      <td>-0.2144373935746069</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7936 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  s_max_S1            s_sum_S1              s_mean_S1  \\\n",
       "0        0.001700947265625  0.5254187902617188  0.0005141084053441476   \n",
       "1       0.0036015025390625          2.49511725  0.0024414063111545987   \n",
       "2       0.0061169798828125            4.491211   0.004394531311154599   \n",
       "3         0.00766963984375          6.48730475   0.006347656311154599   \n",
       "4     0.009855110351562502           8.4833985   0.008300781311154599   \n",
       "...                    ...                 ...                    ...   \n",
       "7931   0.49239281035156246        501.51855625      0.490722657778865   \n",
       "7932     0.493883707421875  503.51464999999996     0.4926757827788649   \n",
       "7933    0.4961542658203125  505.51074374999996     0.4946289077788649   \n",
       "7934    0.4978674255859375  507.50683749999996     0.4965820327788649   \n",
       "7935   0.49994597695312504  509.50293124999996     0.4985351577788649   \n",
       "\n",
       "                    s_std_S1              psd_max_S1             psd_sum_S1  \\\n",
       "0       0.000375134111546019  1.4466108002185822e-06  0.0002069718906404618   \n",
       "1     0.00041312351519890973   6.485410269436816e-06  0.0031330104014424187   \n",
       "2      0.0004915720549679346  1.8708721443366413e-05   0.009991863298801156   \n",
       "3      0.0004465030141622532  2.9411687666418763e-05    0.02069146595454656   \n",
       "4      0.0004174833604398379   4.856160002073719e-05    0.03529848125597924   \n",
       "...                      ...                     ...                    ...   \n",
       "7931  0.00044506303697406735     0.12122533984295487     123.05336064365521   \n",
       "7932  0.00046532519379978156     0.12196055822838811     124.03484781025901   \n",
       "7933   0.0004525283678130062     0.12308452774584668      125.0202181693351   \n",
       "7934  0.00041276876722514424     0.12393598672978451     126.00947557064775   \n",
       "7935  0.00045454396601254764     0.12497298993580731     127.00266768757737   \n",
       "\n",
       "                 psd_mean_S1                  mean_S1               std_S1  \\\n",
       "0     2.0251652704546163e-07   -0.0012994515618164058  0.16106936861370183   \n",
       "1      3.065567907477905e-06   -0.0011206226858398436  0.16205377336559978   \n",
       "2      9.776774264971777e-06  -0.00013747753720703043  0.21131295994117938   \n",
       "3     2.0246052793098393e-05    0.0017813727404296863   0.1838244512744018   \n",
       "4     3.4538631365928804e-05    0.0015248213455078107  0.17145975380650394   \n",
       "...                      ...                      ...                  ...   \n",
       "7931     0.12040446246932995    -0.005335176022753905  0.17912190645622933   \n",
       "7932     0.12136482173215167    -0.004272731928710935  0.18660141904175448   \n",
       "7933     0.12232898059621829   -0.0033993002719726567  0.17105023591780796   \n",
       "7934     0.12329694282842246   -0.0003443699025390616  0.15291595087602328   \n",
       "7935     0.12426875507590741   -0.0003093641684472658   0.1670772703780503   \n",
       "\n",
       "                  median_S1                skew_S1      amp_max_min_S1  \\\n",
       "0              0.0056914465   -0.11066721150373085           0.9869401   \n",
       "1              -0.005452681     0.0944179297661639           1.1304659   \n",
       "2     -0.009470138999999999    0.14395121532071178           1.3191813   \n",
       "3             0.00034578705   0.046062480131920824           1.3538154   \n",
       "4     0.0046324915000000005  -0.023202447658407736           1.1826402   \n",
       "...                     ...                    ...                 ...   \n",
       "7931           -0.002185503  -0.027338265936375988           1.2201605   \n",
       "7932           -0.004680157    0.02906129705454456  1.2731080000000001   \n",
       "7933          -0.0072027485    0.07841541616346018  1.1024421000000002   \n",
       "7934           0.0010140499    0.06107307952190012           0.8754583   \n",
       "7935          -0.0054839625   0.060145534529472605           1.0216575   \n",
       "\n",
       "               kurtosis_S1  damaged  \n",
       "0     -0.09655415028892422        1  \n",
       "1     -0.05224544083007343        1  \n",
       "2     -0.02537046544895416        1  \n",
       "3     0.057745819304428014        1  \n",
       "4      0.07612509751908325        1  \n",
       "...                    ...      ...  \n",
       "7931    0.1292269205289478        0  \n",
       "7932  0.017920414778662686        0  \n",
       "7933  -0.11029827526708935        0  \n",
       "7934  -0.22758344886867787        0  \n",
       "7935   -0.2144373935746069        0  \n",
       "\n",
       "[7936 rows x 14 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_test = defs_.createDatabaseSingleSensor(df_finalB, 1);\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check values from database's target \n",
    "plt.figure()\n",
    "plt.title(\"Representatividade da variável target no dataframe\");\n",
    "plt.xlabel('Valor');\n",
    "plt.ylabel('Quantidade');\n",
    "\n",
    "plt.hist(df_test['damaged'].astype(int),bins = 50,color='purple');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo sem Cross validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos inputs e target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario is: 1\n",
      "X_scaled_train, y_train e X_scaled_test, y_test estão prontos.\n"
     ]
    }
   ],
   "source": [
    "### Setting X and y for model score:0.5545965387932191\n",
    "\n",
    "print('Scenario is: ' + str(1))\n",
    "\n",
    "# Setting target variable\n",
    "y_new_attemp = df_ready['damaged'];\n",
    "y_new_attemp = y_new_attemp.astype(int);\n",
    "\n",
    "# Setting other variables\n",
    "X_new_attemp = df_ready.drop(columns=['damaged']);\n",
    "X_new_attemp = X_new_attemp.astype(float);\n",
    "\n",
    "# Separate database for test and train and \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new_attemp, y_new_attemp, test_size=0.3, shuffle=True);\n",
    "\n",
    "#Scale df\n",
    "std_scaler = StandardScaler()\n",
    "X_scaled_train = pd.DataFrame(std_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index);\n",
    "X_scaled_test = pd.DataFrame(std_scaler.transform(X_test),columns=X_train.columns,index=X_test.index);\n",
    "\n",
    "print('X_scaled_train, y_train e X_scaled_test, y_test estão prontos.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando modelo sem otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preformance de previsão de df de teste: 0.6883\n",
      "Performance de previsão de df de treino: 1.0000\n",
      "-> overfit(?)\n"
     ]
    }
   ],
   "source": [
    "### DEFAULT PARAMETHERS ON FULL DATAFRAME\n",
    "rf = RandomForestClassifier(n_estimators = 5000);\n",
    "rf.fit(X_scaled_train,y_train);\n",
    "\n",
    "### Predict df test\n",
    "y_pred = rf.predict(X_scaled_test);\n",
    "accuracy_test = accuracy_score(y_test, y_pred);\n",
    "print('Preformance de previsão de df de teste: ' + \"{:.4f}\".format(accuracy_test))\n",
    "\n",
    "### Predict df train (overfit)\n",
    "y_pred = rf.predict(X_scaled_train);\n",
    "accuracy_train = accuracy_score(y_train, y_pred);\n",
    "print('Performance de previsão de df de treino: ' + \"{:.4f}\".format(accuracy_train))\n",
    "if (accuracy_train > accuracy_test) :\n",
    "    print('-> overfit(?)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação Database B para teste final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario is: 1\n",
      "PoD: 0.5180191532258065\n"
     ]
    }
   ],
   "source": [
    "### Setting X and y for model score:0.5545965387932191\n",
    "\n",
    "print('Scenario is: ' + str(1))\n",
    "\n",
    "# Setting other variables\n",
    "X_new_attemp = df_test.drop(columns=['damaged']);\n",
    "X_new_attemp = X_new_attemp.astype(float);\n",
    "\n",
    "#Scale df\n",
    "std_scaler = StandardScaler()\n",
    "X_scaled_train = pd.DataFrame(std_scaler.fit_transform(X_new_attemp), columns=X_new_attemp.columns, index=X_new_attemp.index);\n",
    "\n",
    "### Predict df test\n",
    "y_pred = rf.predict(X_scaled_train);\n",
    "pod = defs_.probabilityOfDamage(y_pred);\n",
    "\n",
    "print('PoD: ' + str(pod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 08:30:29,218]\u001b[0m A new study created in memory with name: no-name-fb31f462-213e-4be1-8da5-20dd800c06f4\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 08:30:44,896]\u001b[0m Trial 0 finished with value: 0.6753246753246753 and parameters: {'max_depth': 21, 'max_features': 8}. Best is trial 0 with value: 0.6753246753246753.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 08:30:57,383]\u001b[0m Trial 1 finished with value: 0.6688311688311688 and parameters: {'max_depth': 21, 'max_features': 4}. Best is trial 0 with value: 0.6753246753246753.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 08:31:14,983]\u001b[0m Trial 2 finished with value: 0.6623376623376623 and parameters: {'max_depth': 11, 'max_features': 11}. Best is trial 0 with value: 0.6753246753246753.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 08:31:28,891]\u001b[0m Trial 3 finished with value: 0.6623376623376623 and parameters: {'max_depth': 23, 'max_features': 6}. Best is trial 0 with value: 0.6753246753246753.\u001b[0m\n",
      "\u001b[33m[W 2023-05-30 08:31:34,660]\u001b[0m Trial 4 failed with parameters: {'max_depth': 30, 'max_features': 5} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18280\\4156402354.py\", line 11, in objective\n",
      "    rf.fit(X_scaled_train,y_train);\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 420, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-05-30 08:31:34,667]\u001b[0m Trial 4 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18280\\4156402354.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \"\"\"\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     ):\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18280\\4156402354.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_max_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_max_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m### Predict df test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    935\u001b[0m         \"\"\"\n\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### OPTMAZING PARAMETHERS TO MAXIMIZE SCORE ON QUICK DATAFRAME {'n_estimators': 800, 'max_depth': 2}\n",
    "### last score: 0.5761515497421756\n",
    "\n",
    "def objective(trial):\n",
    "    ### PARAMS\n",
    "    # param_n_estimators = trial.suggest_int('n_estimators',100,100000,100);\n",
    "    param_max_depth = trial.suggest_int('max_depth',1,30,1);\n",
    "    param_max_features = trial.suggest_int('max_features',1,13,1);\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators = 10000, max_depth = param_max_depth, max_features=param_max_features);\n",
    "    rf.fit(X_scaled_train,y_train);\n",
    "\n",
    "    ### Predict df test\n",
    "    y_pred = rf.predict(X_scaled_test);\n",
    "    accuracy_test = accuracy_score(y_test, y_pred);\n",
    "\n",
    "    return accuracy_test \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective,timeout=300)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo com Cross validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos inputs e target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario is: 1\n",
      "X_scaled e y_new_attemp estão prontos.\n"
     ]
    }
   ],
   "source": [
    "### Setting X and y for model\n",
    "\n",
    "print('Scenario is: ' + str(1))\n",
    "\n",
    "# Setting target variable\n",
    "y_new_attemp = df_ready['damaged'];\n",
    "y_new_attemp = y_new_attemp.astype(int);\n",
    "\n",
    "# Setting other variables\n",
    "X_new_attemp = df_ready.drop(columns=['damaged']);\n",
    "X_new_attemp = X_new_attemp.astype(float);\n",
    "\n",
    "#Scale df\n",
    "std_scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(std_scaler.fit_transform(X_new_attemp), columns=X_new_attemp.columns, index=X_new_attemp.index);\n",
    "\n",
    "print('X_scaled e y_new_attemp estão prontos.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando modelo sem otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance da media das validações cruzadas: 0.3635\n"
     ]
    }
   ],
   "source": [
    "### DEFAULT PARAMETHERS ON FULL DATAFRAME\n",
    "score_new_attemp = cross_val_score(XGBClassifier(n_estimators = 1000), X_scaled, y_new_attemp);\n",
    "\n",
    "print('Performance da media das validações cruzadas: ' + \"{:.4f}\".format(np.mean(score_new_attemp)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 00:44:05,132]\u001b[0m A new study created in memory with name: no-name-c1c5f64b-affb-469d-9d41-78b5ed0184e8\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:09,371]\u001b[0m Trial 0 finished with value: 0.3481058442794594 and parameters: {'n_estimators': 950, 'max_depth': 2}. Best is trial 0 with value: 0.3481058442794594.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:13,422]\u001b[0m Trial 1 finished with value: 0.30481629545021893 and parameters: {'n_estimators': 750, 'max_depth': 7}. Best is trial 0 with value: 0.3481058442794594.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:15,212]\u001b[0m Trial 2 finished with value: 0.32623262897391964 and parameters: {'n_estimators': 300, 'max_depth': 13}. Best is trial 0 with value: 0.3481058442794594.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:19,255]\u001b[0m Trial 3 finished with value: 0.3067199695412145 and parameters: {'n_estimators': 700, 'max_depth': 9}. Best is trial 0 with value: 0.3481058442794594.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:22,710]\u001b[0m Trial 4 finished with value: 0.3203883495145631 and parameters: {'n_estimators': 600, 'max_depth': 14}. Best is trial 0 with value: 0.3481058442794594.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:26,226]\u001b[0m Trial 5 finished with value: 0.31846563868265754 and parameters: {'n_estimators': 600, 'max_depth': 13}. Best is trial 0 with value: 0.3481058442794594.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:28,638]\u001b[0m Trial 6 finished with value: 0.36767561393489434 and parameters: {'n_estimators': 550, 'max_depth': 2}. Best is trial 6 with value: 0.36767561393489434.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:31,522]\u001b[0m Trial 7 finished with value: 0.2989529792499524 and parameters: {'n_estimators': 550, 'max_depth': 5}. Best is trial 6 with value: 0.36767561393489434.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:32,128]\u001b[0m Trial 8 finished with value: 0.312602322482391 and parameters: {'n_estimators': 100, 'max_depth': 12}. Best is trial 6 with value: 0.36767561393489434.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:32,661]\u001b[0m Trial 9 finished with value: 0.30479725870930896 and parameters: {'n_estimators': 100, 'max_depth': 6}. Best is trial 6 with value: 0.36767561393489434.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:34,134]\u001b[0m Trial 10 finished with value: 0.43624595469255667 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 10 with value: 0.43624595469255667.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:35,594]\u001b[0m Trial 11 finished with value: 0.492594707786027 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:37,032]\u001b[0m Trial 12 finished with value: 0.4925375975632972 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:38,751]\u001b[0m Trial 13 finished with value: 0.30295069484104326 and parameters: {'n_estimators': 350, 'max_depth': 4}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:40,219]\u001b[0m Trial 14 finished with value: 0.30868075385494 and parameters: {'n_estimators': 250, 'max_depth': 9}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:42,392]\u001b[0m Trial 15 finished with value: 0.334342280601561 and parameters: {'n_estimators': 450, 'max_depth': 3}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:43,212]\u001b[0m Trial 16 finished with value: 0.4886160289358462 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:45,561]\u001b[0m Trial 17 finished with value: 0.30489244241385877 and parameters: {'n_estimators': 450, 'max_depth': 4}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:48,150]\u001b[0m Trial 18 finished with value: 0.32236817056919853 and parameters: {'n_estimators': 450, 'max_depth': 11}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:49,087]\u001b[0m Trial 19 finished with value: 0.33826384922901204 and parameters: {'n_estimators': 200, 'max_depth': 3}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:54,430]\u001b[0m Trial 20 finished with value: 0.30673900628212447 and parameters: {'n_estimators': 1000, 'max_depth': 7}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:55,283]\u001b[0m Trial 21 finished with value: 0.4886541024176661 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:56,920]\u001b[0m Trial 22 finished with value: 0.49257567104511707 and parameters: {'n_estimators': 400, 'max_depth': 1}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:44:58,547]\u001b[0m Trial 23 finished with value: 0.32845992766038457 and parameters: {'n_estimators': 350, 'max_depth': 3}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:00,880]\u001b[0m Trial 24 finished with value: 0.29505044736341135 and parameters: {'n_estimators': 450, 'max_depth': 5}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:02,602]\u001b[0m Trial 25 finished with value: 0.3481058442794593 and parameters: {'n_estimators': 400, 'max_depth': 2}. Best is trial 11 with value: 0.492594707786027.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:03,868]\u001b[0m Trial 26 finished with value: 0.4984580239862935 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:05,128]\u001b[0m Trial 27 finished with value: 0.3108128688368551 and parameters: {'n_estimators': 250, 'max_depth': 4}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:08,143]\u001b[0m Trial 28 finished with value: 0.3696744717304397 and parameters: {'n_estimators': 700, 'max_depth': 2}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:08,850]\u001b[0m Trial 29 finished with value: 0.3264991433466591 and parameters: {'n_estimators': 150, 'max_depth': 3}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:12,319]\u001b[0m Trial 30 finished with value: 0.4886541024176661 and parameters: {'n_estimators': 850, 'max_depth': 1}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:13,546]\u001b[0m Trial 31 finished with value: 0.4828859699219493 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:15,312]\u001b[0m Trial 32 finished with value: 0.3579097658480868 and parameters: {'n_estimators': 400, 'max_depth': 2}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:16,623]\u001b[0m Trial 33 finished with value: 0.3578716923662669 and parameters: {'n_estimators': 300, 'max_depth': 2}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:19,123]\u001b[0m Trial 34 finished with value: 0.29505044736341135 and parameters: {'n_estimators': 500, 'max_depth': 5}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:20,347]\u001b[0m Trial 35 finished with value: 0.4866933181039406 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:21,571]\u001b[0m Trial 36 finished with value: 0.334342280601561 and parameters: {'n_estimators': 250, 'max_depth': 3}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:23,733]\u001b[0m Trial 37 finished with value: 0.3067390062821245 and parameters: {'n_estimators': 400, 'max_depth': 8}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:26,676]\u001b[0m Trial 38 finished with value: 0.2951456310679611 and parameters: {'n_estimators': 600, 'max_depth': 4}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:29,487]\u001b[0m Trial 39 finished with value: 0.3223872073101085 and parameters: {'n_estimators': 500, 'max_depth': 15}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:30,971]\u001b[0m Trial 40 finished with value: 0.3637540453074434 and parameters: {'n_estimators': 350, 'max_depth': 2}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:31,766]\u001b[0m Trial 41 finished with value: 0.4614125261755187 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 26 with value: 0.4984580239862935.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:32,738]\u001b[0m Trial 42 finished with value: 0.5062440510184656 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:33,839]\u001b[0m Trial 43 finished with value: 0.3617932609937179 and parameters: {'n_estimators': 250, 'max_depth': 2}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:34,470]\u001b[0m Trial 44 finished with value: 0.45947077860270313 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:36,459]\u001b[0m Trial 45 finished with value: 0.31844660194174756 and parameters: {'n_estimators': 350, 'max_depth': 10}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:38,204]\u001b[0m Trial 46 finished with value: 0.35398819722063585 and parameters: {'n_estimators': 400, 'max_depth': 2}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:39,811]\u001b[0m Trial 47 finished with value: 0.30477822196839904 and parameters: {'n_estimators': 300, 'max_depth': 6}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:42,133]\u001b[0m Trial 48 finished with value: 0.33043974871502 and parameters: {'n_estimators': 500, 'max_depth': 3}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:42,758]\u001b[0m Trial 49 finished with value: 0.4925375975632972 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:45,684]\u001b[0m Trial 50 finished with value: 0.34022463354273746 and parameters: {'n_estimators': 650, 'max_depth': 3}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:46,095]\u001b[0m Trial 51 finished with value: 0.4906529602132115 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:46,733]\u001b[0m Trial 52 finished with value: 0.33828288596992195 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:47,713]\u001b[0m Trial 53 finished with value: 0.4576432514753474 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:49,092]\u001b[0m Trial 54 finished with value: 0.4945174186179326 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:50,498]\u001b[0m Trial 55 finished with value: 0.3068722634684942 and parameters: {'n_estimators': 300, 'max_depth': 4}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:51,979]\u001b[0m Trial 56 finished with value: 0.3774985722444317 and parameters: {'n_estimators': 350, 'max_depth': 2}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:54,175]\u001b[0m Trial 57 finished with value: 0.32234913382828856 and parameters: {'n_estimators': 400, 'max_depth': 13}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:55,850]\u001b[0m Trial 58 finished with value: 0.3402246335427375 and parameters: {'n_estimators': 350, 'max_depth': 3}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:45:57,871]\u001b[0m Trial 59 finished with value: 0.4905958499904816 and parameters: {'n_estimators': 450, 'max_depth': 1}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:00,364]\u001b[0m Trial 60 finished with value: 0.3656957928802589 and parameters: {'n_estimators': 550, 'max_depth': 2}. Best is trial 42 with value: 0.5062440510184656.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:01,465]\u001b[0m Trial 61 finished with value: 0.5120883304778221 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:02,591]\u001b[0m Trial 62 finished with value: 0.43613173424709684 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:03,900]\u001b[0m Trial 63 finished with value: 0.49840091376356366 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:04,741]\u001b[0m Trial 64 finished with value: 0.488673139158576 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:05,895]\u001b[0m Trial 65 finished with value: 0.3735960403578907 and parameters: {'n_estimators': 250, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:07,194]\u001b[0m Trial 66 finished with value: 0.34024367028364744 and parameters: {'n_estimators': 300, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:08,298]\u001b[0m Trial 67 finished with value: 0.342185417856463 and parameters: {'n_estimators': 250, 'max_depth': 3}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:09,458]\u001b[0m Trial 68 finished with value: 0.4925566343042071 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:13,001]\u001b[0m Trial 69 finished with value: 0.34022463354273746 and parameters: {'n_estimators': 800, 'max_depth': 3}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:13,618]\u001b[0m Trial 70 finished with value: 0.49649723967256804 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:14,035]\u001b[0m Trial 71 finished with value: 0.4964210927089282 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:14,459]\u001b[0m Trial 72 finished with value: 0.3618313344755378 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:15,143]\u001b[0m Trial 73 finished with value: 0.43034456501047014 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:15,568]\u001b[0m Trial 74 finished with value: 0.49647820293165806 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:16,096]\u001b[0m Trial 75 finished with value: 0.4323053493241956 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:16,608]\u001b[0m Trial 76 finished with value: 0.3735960403578907 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:17,297]\u001b[0m Trial 77 finished with value: 0.3716352560441652 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:18,083]\u001b[0m Trial 78 finished with value: 0.49647820293165806 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:18,862]\u001b[0m Trial 79 finished with value: 0.4925375975632972 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:19,317]\u001b[0m Trial 80 finished with value: 0.36379211878926326 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:19,965]\u001b[0m Trial 81 finished with value: 0.4362269179516467 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:20,782]\u001b[0m Trial 82 finished with value: 0.4440890919474586 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:21,483]\u001b[0m Trial 83 finished with value: 0.36571482962116886 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:22,327]\u001b[0m Trial 84 finished with value: 0.48284789644012943 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:23,610]\u001b[0m Trial 85 finished with value: 0.34022463354273746 and parameters: {'n_estimators': 250, 'max_depth': 3}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:24,071]\u001b[0m Trial 86 finished with value: 0.4886541024176661 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:25,305]\u001b[0m Trial 87 finished with value: 0.3125832857414811 and parameters: {'n_estimators': 200, 'max_depth': 8}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:26,037]\u001b[0m Trial 88 finished with value: 0.3500095183704549 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:27,220]\u001b[0m Trial 89 finished with value: 0.2990671996954122 and parameters: {'n_estimators': 200, 'max_depth': 4}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:28,296]\u001b[0m Trial 90 finished with value: 0.48667428136303065 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:29,340]\u001b[0m Trial 91 finished with value: 0.4576242147344374 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:30,635]\u001b[0m Trial 92 finished with value: 0.4886160289358461 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:31,121]\u001b[0m Trial 93 finished with value: 0.350028555111365 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:31,784]\u001b[0m Trial 94 finished with value: 0.4691604797258709 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:33,373]\u001b[0m Trial 95 finished with value: 0.3735960403578907 and parameters: {'n_estimators': 350, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:34,883]\u001b[0m Trial 96 finished with value: 0.320426422996383 and parameters: {'n_estimators': 250, 'max_depth': 11}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:35,728]\u001b[0m Trial 97 finished with value: 0.47121644774414617 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:37,068]\u001b[0m Trial 98 finished with value: 0.3480487340567294 and parameters: {'n_estimators': 300, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:40,970]\u001b[0m Trial 99 finished with value: 0.338263849229012 and parameters: {'n_estimators': 900, 'max_depth': 3}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:41,755]\u001b[0m Trial 100 finished with value: 0.31454407005520657 and parameters: {'n_estimators': 150, 'max_depth': 7}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:43,113]\u001b[0m Trial 101 finished with value: 0.44210927089282315 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:44,675]\u001b[0m Trial 102 finished with value: 0.4906529602132115 and parameters: {'n_estimators': 400, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:45,872]\u001b[0m Trial 103 finished with value: 0.4788311441081287 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:47,722]\u001b[0m Trial 104 finished with value: 0.3735579668760708 and parameters: {'n_estimators': 450, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:49,098]\u001b[0m Trial 105 finished with value: 0.4906148867313916 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:50,782]\u001b[0m Trial 106 finished with value: 0.3657338663620788 and parameters: {'n_estimators': 400, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:52,264]\u001b[0m Trial 107 finished with value: 0.3028555111364934 and parameters: {'n_estimators': 300, 'max_depth': 6}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:53,237]\u001b[0m Trial 108 finished with value: 0.48671235484485054 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:54,292]\u001b[0m Trial 109 finished with value: 0.3164858176280221 and parameters: {'n_estimators': 200, 'max_depth': 9}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:54,736]\u001b[0m Trial 110 finished with value: 0.3617742242528079 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:55,735]\u001b[0m Trial 111 finished with value: 0.5120502569960023 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:56,710]\u001b[0m Trial 112 finished with value: 0.49067199695412145 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:58,079]\u001b[0m Trial 113 finished with value: 0.43620788121073667 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:46:59,318]\u001b[0m Trial 114 finished with value: 0.3716162193032552 and parameters: {'n_estimators': 300, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:00,104]\u001b[0m Trial 115 finished with value: 0.47702265372168284 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:01,095]\u001b[0m Trial 116 finished with value: 0.47894536455358844 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:01,727]\u001b[0m Trial 117 finished with value: 0.3637730820483533 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:02,358]\u001b[0m Trial 118 finished with value: 0.5082048353321911 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:02,766]\u001b[0m Trial 119 finished with value: 0.48292404340376927 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:03,396]\u001b[0m Trial 120 finished with value: 0.3716162193032552 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:04,181]\u001b[0m Trial 121 finished with value: 0.4925566343042071 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:04,784]\u001b[0m Trial 122 finished with value: 0.4323053493241956 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:05,967]\u001b[0m Trial 123 finished with value: 0.4906148867313916 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:06,806]\u001b[0m Trial 124 finished with value: 0.3873024938130592 and parameters: {'n_estimators': 200, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:07,822]\u001b[0m Trial 125 finished with value: 0.4906148867313916 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:08,233]\u001b[0m Trial 126 finished with value: 0.48088711212640395 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:08,665]\u001b[0m Trial 127 finished with value: 0.35004759185227485 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:09,277]\u001b[0m Trial 128 finished with value: 0.43624595469255667 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:10,975]\u001b[0m Trial 129 finished with value: 0.35594898153436133 and parameters: {'n_estimators': 400, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:12,083]\u001b[0m Trial 130 finished with value: 0.3441462021701885 and parameters: {'n_estimators': 250, 'max_depth': 3}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:13,264]\u001b[0m Trial 131 finished with value: 0.48863506567675613 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:14,435]\u001b[0m Trial 132 finished with value: 0.4381686655244622 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:15,852]\u001b[0m Trial 133 finished with value: 0.4925185608223872 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:16,644]\u001b[0m Trial 134 finished with value: 0.4867504283266705 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:18,024]\u001b[0m Trial 135 finished with value: 0.4867504283266705 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:19,067]\u001b[0m Trial 136 finished with value: 0.35981343993908244 and parameters: {'n_estimators': 250, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:19,685]\u001b[0m Trial 137 finished with value: 0.5042451932229202 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:20,282]\u001b[0m Trial 138 finished with value: 0.4441081286883685 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:21,170]\u001b[0m Trial 139 finished with value: 0.3873215305539691 and parameters: {'n_estimators': 200, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:21,931]\u001b[0m Trial 140 finished with value: 0.29505044736341135 and parameters: {'n_estimators': 150, 'max_depth': 5}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:25,268]\u001b[0m Trial 141 finished with value: 0.320426422996383 and parameters: {'n_estimators': 600, 'max_depth': 15}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:25,691]\u001b[0m Trial 142 finished with value: 0.4672187321530554 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:26,878]\u001b[0m Trial 143 finished with value: 0.4654292785075195 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:27,482]\u001b[0m Trial 144 finished with value: 0.48671235484485054 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:28,279]\u001b[0m Trial 145 finished with value: 0.49457452884066244 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:29,109]\u001b[0m Trial 146 finished with value: 0.3794783932990672 and parameters: {'n_estimators': 200, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:29,957]\u001b[0m Trial 147 finished with value: 0.3735579668760708 and parameters: {'n_estimators': 200, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:30,374]\u001b[0m Trial 148 finished with value: 0.44601180277936414 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:33,871]\u001b[0m Trial 149 finished with value: 0.32036931277365316 and parameters: {'n_estimators': 650, 'max_depth': 10}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:35,246]\u001b[0m Trial 150 finished with value: 0.3164858176280221 and parameters: {'n_estimators': 250, 'max_depth': 14}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:36,272]\u001b[0m Trial 151 finished with value: 0.47698458023986295 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:37,451]\u001b[0m Trial 152 finished with value: 0.48871121264039596 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:38,812]\u001b[0m Trial 153 finished with value: 0.49453645535884255 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:40,394]\u001b[0m Trial 154 finished with value: 0.492594707786027 and parameters: {'n_estimators': 400, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:41,784]\u001b[0m Trial 155 finished with value: 0.48469446030839514 and parameters: {'n_estimators': 350, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:45,612]\u001b[0m Trial 156 finished with value: 0.4925566343042071 and parameters: {'n_estimators': 1000, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:46,241]\u001b[0m Trial 157 finished with value: 0.49449838187702266 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:46,878]\u001b[0m Trial 158 finished with value: 0.36769465067580426 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:47,674]\u001b[0m Trial 159 finished with value: 0.49453645535884255 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:48,463]\u001b[0m Trial 160 finished with value: 0.4905958499904816 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:49,060]\u001b[0m Trial 161 finished with value: 0.48092518560822384 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:49,850]\u001b[0m Trial 162 finished with value: 0.488692175899486 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:50,484]\u001b[0m Trial 163 finished with value: 0.3461069864839139 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:51,296]\u001b[0m Trial 164 finished with value: 0.49841995050447363 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:52,082]\u001b[0m Trial 165 finished with value: 0.4983818770226537 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:52,874]\u001b[0m Trial 166 finished with value: 0.48277174947648954 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:53,853]\u001b[0m Trial 167 finished with value: 0.49649723967256804 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:54,901]\u001b[0m Trial 168 finished with value: 0.35202741290691036 and parameters: {'n_estimators': 250, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:55,716]\u001b[0m Trial 169 finished with value: 0.43226727584237573 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:56,724]\u001b[0m Trial 170 finished with value: 0.49257567104511707 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:57,512]\u001b[0m Trial 171 finished with value: 0.5042832667047401 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:58,290]\u001b[0m Trial 172 finished with value: 0.4867694650675804 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:47:59,074]\u001b[0m Trial 173 finished with value: 0.4323053493241956 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:00,128]\u001b[0m Trial 174 finished with value: 0.36769465067580426 and parameters: {'n_estimators': 250, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:00,930]\u001b[0m Trial 175 finished with value: 0.48871121264039596 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:01,745]\u001b[0m Trial 176 finished with value: 0.4808300019036741 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:02,169]\u001b[0m Trial 177 finished with value: 0.4634113839710642 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:03,218]\u001b[0m Trial 178 finished with value: 0.3735579668760708 and parameters: {'n_estimators': 250, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:03,827]\u001b[0m Trial 179 finished with value: 0.48084903864458406 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:04,464]\u001b[0m Trial 180 finished with value: 0.4010089472682276 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:05,433]\u001b[0m Trial 181 finished with value: 0.4886541024176661 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:06,252]\u001b[0m Trial 182 finished with value: 0.47702265372168284 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:07,238]\u001b[0m Trial 183 finished with value: 0.4925375975632972 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:07,847]\u001b[0m Trial 184 finished with value: 0.4905577765086617 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:08,261]\u001b[0m Trial 185 finished with value: 0.48277174947648954 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:09,243]\u001b[0m Trial 186 finished with value: 0.48871121264039596 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:10,094]\u001b[0m Trial 187 finished with value: 0.3735579668760708 and parameters: {'n_estimators': 200, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:10,881]\u001b[0m Trial 188 finished with value: 0.4672377688939653 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:11,294]\u001b[0m Trial 189 finished with value: 0.43034456501047014 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:11,896]\u001b[0m Trial 190 finished with value: 0.5042451932229202 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:12,502]\u001b[0m Trial 191 finished with value: 0.5003807348181991 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:13,103]\u001b[0m Trial 192 finished with value: 0.4671806586712354 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:13,694]\u001b[0m Trial 193 finished with value: 0.4868456120312203 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:14,295]\u001b[0m Trial 194 finished with value: 0.49449838187702266 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:15,081]\u001b[0m Trial 195 finished with value: 0.4866933181039405 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:15,681]\u001b[0m Trial 196 finished with value: 0.44978107747953544 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:16,119]\u001b[0m Trial 197 finished with value: 0.36175518751189795 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:16,918]\u001b[0m Trial 198 finished with value: 0.48471349704930516 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:17,350]\u001b[0m Trial 199 finished with value: 0.334361317342471 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:18,135]\u001b[0m Trial 200 finished with value: 0.48280982295830943 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:18,768]\u001b[0m Trial 201 finished with value: 0.4983818770226537 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:19,364]\u001b[0m Trial 202 finished with value: 0.4769084332762231 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:19,962]\u001b[0m Trial 203 finished with value: 0.44012944983818764 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:20,750]\u001b[0m Trial 204 finished with value: 0.4867313915857605 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:21,349]\u001b[0m Trial 205 finished with value: 0.49263278126784693 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:21,770]\u001b[0m Trial 206 finished with value: 0.4361888444698268 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:22,745]\u001b[0m Trial 207 finished with value: 0.4692556634304207 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:23,552]\u001b[0m Trial 208 finished with value: 0.44407005520654863 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:24,191]\u001b[0m Trial 209 finished with value: 0.3892632781267847 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:24,993]\u001b[0m Trial 210 finished with value: 0.4381877022653722 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:26,041]\u001b[0m Trial 211 finished with value: 0.488692175899486 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:27,238]\u001b[0m Trial 212 finished with value: 0.48086807538549403 and parameters: {'n_estimators': 300, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:27,842]\u001b[0m Trial 213 finished with value: 0.49455549209975247 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:28,453]\u001b[0m Trial 214 finished with value: 0.4186369693508471 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:28,873]\u001b[0m Trial 215 finished with value: 0.4867694650675804 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:29,715]\u001b[0m Trial 216 finished with value: 0.36571482962116886 and parameters: {'n_estimators': 200, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:30,466]\u001b[0m Trial 217 finished with value: 0.3028555111364934 and parameters: {'n_estimators': 150, 'max_depth': 6}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:30,884]\u001b[0m Trial 218 finished with value: 0.49651627641347795 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:31,447]\u001b[0m Trial 219 finished with value: 0.320426422996383 and parameters: {'n_estimators': 100, 'max_depth': 12}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:31,860]\u001b[0m Trial 220 finished with value: 0.5042071197411003 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:32,273]\u001b[0m Trial 221 finished with value: 0.49053873976775175 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:32,685]\u001b[0m Trial 222 finished with value: 0.4828669331810394 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:33,088]\u001b[0m Trial 223 finished with value: 0.4420902341519132 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:33,497]\u001b[0m Trial 224 finished with value: 0.48671235484485054 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:34,095]\u001b[0m Trial 225 finished with value: 0.4691604797258709 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:36,994]\u001b[0m Trial 226 finished with value: 0.4828288596992195 and parameters: {'n_estimators': 750, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:37,587]\u001b[0m Trial 227 finished with value: 0.49449838187702266 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:38,021]\u001b[0m Trial 228 finished with value: 0.3441652389110984 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:38,616]\u001b[0m Trial 229 finished with value: 0.4460308395202741 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:39,227]\u001b[0m Trial 230 finished with value: 0.49843898724538355 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:39,824]\u001b[0m Trial 231 finished with value: 0.49840091376356366 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:40,478]\u001b[0m Trial 232 finished with value: 0.49257567104511707 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:41,071]\u001b[0m Trial 233 finished with value: 0.484770607272035 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:41,486]\u001b[0m Trial 234 finished with value: 0.47890729107176855 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:42,083]\u001b[0m Trial 235 finished with value: 0.43038263849229014 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:42,680]\u001b[0m Trial 236 finished with value: 0.48859699219493624 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:43,083]\u001b[0m Trial 237 finished with value: 0.47698458023986295 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:43,679]\u001b[0m Trial 238 finished with value: 0.4925566343042071 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:44,525]\u001b[0m Trial 239 finished with value: 0.3696744717304397 and parameters: {'n_estimators': 200, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:44,938]\u001b[0m Trial 240 finished with value: 0.4886160289358462 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:45,720]\u001b[0m Trial 241 finished with value: 0.4945174186179326 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:46,320]\u001b[0m Trial 242 finished with value: 0.4828859699219493 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:48,247]\u001b[0m Trial 243 finished with value: 0.4886160289358461 and parameters: {'n_estimators': 500, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:49,267]\u001b[0m Trial 244 finished with value: 0.4499524081477251 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:50,053]\u001b[0m Trial 245 finished with value: 0.44210927089282315 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:50,463]\u001b[0m Trial 246 finished with value: 0.4905577765086617 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:51,112]\u001b[0m Trial 247 finished with value: 0.3363030649152865 and parameters: {'n_estimators': 150, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:52,113]\u001b[0m Trial 248 finished with value: 0.5003807348181991 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:53,082]\u001b[0m Trial 249 finished with value: 0.4866933181039405 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:54,080]\u001b[0m Trial 250 finished with value: 0.484770607272035 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:54,904]\u001b[0m Trial 251 finished with value: 0.3676946506758043 and parameters: {'n_estimators': 200, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:55,901]\u001b[0m Trial 252 finished with value: 0.4342661336379211 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:56,513]\u001b[0m Trial 253 finished with value: 0.4945174186179326 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:57,110]\u001b[0m Trial 254 finished with value: 0.4905958499904816 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:57,890]\u001b[0m Trial 255 finished with value: 0.45372168284789643 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:58,324]\u001b[0m Trial 256 finished with value: 0.4068341899866742 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:59,118]\u001b[0m Trial 257 finished with value: 0.4770416904625928 and parameters: {'n_estimators': 200, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:48:59,740]\u001b[0m Trial 258 finished with value: 0.43820673900628215 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:49:00,279]\u001b[0m Trial 259 finished with value: 0.2969921949362269 and parameters: {'n_estimators': 100, 'max_depth': 7}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:49:01,264]\u001b[0m Trial 260 finished with value: 0.46156482010279837 and parameters: {'n_estimators': 250, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:49:01,862]\u001b[0m Trial 261 finished with value: 0.47127355796687603 and parameters: {'n_estimators': 150, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:49:02,710]\u001b[0m Trial 262 finished with value: 0.3971064153816866 and parameters: {'n_estimators': 200, 'max_depth': 2}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 00:49:06,387]\u001b[0m Trial 263 finished with value: 0.484732533790215 and parameters: {'n_estimators': 950, 'max_depth': 1}. Best is trial 61 with value: 0.5120883304778221.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200, 'max_depth': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OPTMAZING PARAMETHERS TO MAXIMIZE SCORE ON QUICK DATAFRAME {'n_estimators': 800, 'max_depth': 2}\n",
    "### last score: 0.5761515497421756\n",
    "\n",
    "def objective(trial):\n",
    "    ### PARAMS\n",
    "    param_n_estimators = trial.suggest_int('n_estimators',100,1000,50);\n",
    "    param_max_depth = trial.suggest_int('max_depth',1,15,1);\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators = param_n_estimators, max_depth = param_max_depth);\n",
    "\n",
    "    score_def = cross_val_score(rf, X_new_attemp, y_new_attemp);\n",
    "    score_def.astype(float);\n",
    "    return np.mean(score_def) \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, timeout=300)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263
         ],
         "y": [
          0.3481058442794594,
          0.30481629545021893,
          0.32623262897391964,
          0.3067199695412145,
          0.3203883495145631,
          0.31846563868265754,
          0.36767561393489434,
          0.2989529792499524,
          0.312602322482391,
          0.30479725870930896,
          0.43624595469255667,
          0.492594707786027,
          0.4925375975632972,
          0.30295069484104326,
          0.30868075385494,
          0.334342280601561,
          0.4886160289358462,
          0.30489244241385877,
          0.32236817056919853,
          0.33826384922901204,
          0.30673900628212447,
          0.4886541024176661,
          0.49257567104511707,
          0.32845992766038457,
          0.29505044736341135,
          0.3481058442794593,
          0.4984580239862935,
          0.3108128688368551,
          0.3696744717304397,
          0.3264991433466591,
          0.4886541024176661,
          0.4828859699219493,
          0.3579097658480868,
          0.3578716923662669,
          0.29505044736341135,
          0.4866933181039406,
          0.334342280601561,
          0.3067390062821245,
          0.2951456310679611,
          0.3223872073101085,
          0.3637540453074434,
          0.4614125261755187,
          0.5062440510184656,
          0.3617932609937179,
          0.45947077860270313,
          0.31844660194174756,
          0.35398819722063585,
          0.30477822196839904,
          0.33043974871502,
          0.4925375975632972,
          0.34022463354273746,
          0.4906529602132115,
          0.33828288596992195,
          0.4576432514753474,
          0.4945174186179326,
          0.3068722634684942,
          0.3774985722444317,
          0.32234913382828856,
          0.3402246335427375,
          0.4905958499904816,
          0.3656957928802589,
          0.5120883304778221,
          0.43613173424709684,
          0.49840091376356366,
          0.488673139158576,
          0.3735960403578907,
          0.34024367028364744,
          0.342185417856463,
          0.4925566343042071,
          0.34022463354273746,
          0.49649723967256804,
          0.4964210927089282,
          0.3618313344755378,
          0.43034456501047014,
          0.49647820293165806,
          0.4323053493241956,
          0.3735960403578907,
          0.3716352560441652,
          0.49647820293165806,
          0.4925375975632972,
          0.36379211878926326,
          0.4362269179516467,
          0.4440890919474586,
          0.36571482962116886,
          0.48284789644012943,
          0.34022463354273746,
          0.4886541024176661,
          0.3125832857414811,
          0.3500095183704549,
          0.2990671996954122,
          0.48667428136303065,
          0.4576242147344374,
          0.4886160289358461,
          0.350028555111365,
          0.4691604797258709,
          0.3735960403578907,
          0.320426422996383,
          0.47121644774414617,
          0.3480487340567294,
          0.338263849229012,
          0.31454407005520657,
          0.44210927089282315,
          0.4906529602132115,
          0.4788311441081287,
          0.3735579668760708,
          0.4906148867313916,
          0.3657338663620788,
          0.3028555111364934,
          0.48671235484485054,
          0.3164858176280221,
          0.3617742242528079,
          0.5120502569960023,
          0.49067199695412145,
          0.43620788121073667,
          0.3716162193032552,
          0.47702265372168284,
          0.47894536455358844,
          0.3637730820483533,
          0.5082048353321911,
          0.48292404340376927,
          0.3716162193032552,
          0.4925566343042071,
          0.4323053493241956,
          0.4906148867313916,
          0.3873024938130592,
          0.4906148867313916,
          0.48088711212640395,
          0.35004759185227485,
          0.43624595469255667,
          0.35594898153436133,
          0.3441462021701885,
          0.48863506567675613,
          0.4381686655244622,
          0.4925185608223872,
          0.4867504283266705,
          0.4867504283266705,
          0.35981343993908244,
          0.5042451932229202,
          0.4441081286883685,
          0.3873215305539691,
          0.29505044736341135,
          0.320426422996383,
          0.4672187321530554,
          0.4654292785075195,
          0.48671235484485054,
          0.49457452884066244,
          0.3794783932990672,
          0.3735579668760708,
          0.44601180277936414,
          0.32036931277365316,
          0.3164858176280221,
          0.47698458023986295,
          0.48871121264039596,
          0.49453645535884255,
          0.492594707786027,
          0.48469446030839514,
          0.4925566343042071,
          0.49449838187702266,
          0.36769465067580426,
          0.49453645535884255,
          0.4905958499904816,
          0.48092518560822384,
          0.488692175899486,
          0.3461069864839139,
          0.49841995050447363,
          0.4983818770226537,
          0.48277174947648954,
          0.49649723967256804,
          0.35202741290691036,
          0.43226727584237573,
          0.49257567104511707,
          0.5042832667047401,
          0.4867694650675804,
          0.4323053493241956,
          0.36769465067580426,
          0.48871121264039596,
          0.4808300019036741,
          0.4634113839710642,
          0.3735579668760708,
          0.48084903864458406,
          0.4010089472682276,
          0.4886541024176661,
          0.47702265372168284,
          0.4925375975632972,
          0.4905577765086617,
          0.48277174947648954,
          0.48871121264039596,
          0.3735579668760708,
          0.4672377688939653,
          0.43034456501047014,
          0.5042451932229202,
          0.5003807348181991,
          0.4671806586712354,
          0.4868456120312203,
          0.49449838187702266,
          0.4866933181039405,
          0.44978107747953544,
          0.36175518751189795,
          0.48471349704930516,
          0.334361317342471,
          0.48280982295830943,
          0.4983818770226537,
          0.4769084332762231,
          0.44012944983818764,
          0.4867313915857605,
          0.49263278126784693,
          0.4361888444698268,
          0.4692556634304207,
          0.44407005520654863,
          0.3892632781267847,
          0.4381877022653722,
          0.488692175899486,
          0.48086807538549403,
          0.49455549209975247,
          0.4186369693508471,
          0.4867694650675804,
          0.36571482962116886,
          0.3028555111364934,
          0.49651627641347795,
          0.320426422996383,
          0.5042071197411003,
          0.49053873976775175,
          0.4828669331810394,
          0.4420902341519132,
          0.48671235484485054,
          0.4691604797258709,
          0.4828288596992195,
          0.49449838187702266,
          0.3441652389110984,
          0.4460308395202741,
          0.49843898724538355,
          0.49840091376356366,
          0.49257567104511707,
          0.484770607272035,
          0.47890729107176855,
          0.43038263849229014,
          0.48859699219493624,
          0.47698458023986295,
          0.4925566343042071,
          0.3696744717304397,
          0.4886160289358462,
          0.4945174186179326,
          0.4828859699219493,
          0.4886160289358461,
          0.4499524081477251,
          0.44210927089282315,
          0.4905577765086617,
          0.3363030649152865,
          0.5003807348181991,
          0.4866933181039405,
          0.484770607272035,
          0.3676946506758043,
          0.4342661336379211,
          0.4945174186179326,
          0.4905958499904816,
          0.45372168284789643,
          0.4068341899866742,
          0.4770416904625928,
          0.43820673900628215,
          0.2969921949362269,
          0.46156482010279837,
          0.47127355796687603,
          0.3971064153816866,
          0.484732533790215
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263
         ],
         "y": [
          0.3481058442794594,
          0.3481058442794594,
          0.3481058442794594,
          0.3481058442794594,
          0.3481058442794594,
          0.3481058442794594,
          0.36767561393489434,
          0.36767561393489434,
          0.36767561393489434,
          0.36767561393489434,
          0.43624595469255667,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.492594707786027,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.4984580239862935,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5062440510184656,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221,
          0.5120883304778221
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_S1</th>\n",
       "      <th>std_S1</th>\n",
       "      <th>median_S1</th>\n",
       "      <th>skew_S1</th>\n",
       "      <th>amp_max_min_S1</th>\n",
       "      <th>kurtosis_S1</th>\n",
       "      <th>damaged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000414370442</td>\n",
       "      <td>0.043120406327645536</td>\n",
       "      <td>-0.003243883</td>\n",
       "      <td>-0.41442675239991716</td>\n",
       "      <td>0.18522184</td>\n",
       "      <td>0.18229650179968981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.00149953008</td>\n",
       "      <td>0.08873689907904413</td>\n",
       "      <td>-0.0073719135000000005</td>\n",
       "      <td>-0.008557772829157796</td>\n",
       "      <td>0.3630676</td>\n",
       "      <td>-0.6650972729370102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002099744577200001</td>\n",
       "      <td>0.12369873116059492</td>\n",
       "      <td>-0.01570684</td>\n",
       "      <td>0.588571492652289</td>\n",
       "      <td>0.6131021999999999</td>\n",
       "      <td>0.7530364721892133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0033677626000000005</td>\n",
       "      <td>0.1388221230414223</td>\n",
       "      <td>-0.042125805</td>\n",
       "      <td>0.26839345162009703</td>\n",
       "      <td>0.5585321</td>\n",
       "      <td>-0.7062843969531509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0033172219000000003</td>\n",
       "      <td>0.13300805870201626</td>\n",
       "      <td>-0.0047542875</td>\n",
       "      <td>0.3868517885124701</td>\n",
       "      <td>0.5399411000000001</td>\n",
       "      <td>-0.14875481556053805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162528</th>\n",
       "      <td>0.014895218723999999</td>\n",
       "      <td>0.1436816838486326</td>\n",
       "      <td>-0.0041809065</td>\n",
       "      <td>1.12900580926754</td>\n",
       "      <td>0.8092328</td>\n",
       "      <td>3.0430900402674945</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162529</th>\n",
       "      <td>0.014240604980000002</td>\n",
       "      <td>0.13816677091787724</td>\n",
       "      <td>0.0084757445</td>\n",
       "      <td>-0.042066688930058285</td>\n",
       "      <td>0.6926772000000001</td>\n",
       "      <td>0.1608569660924406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162530</th>\n",
       "      <td>-0.0018931615239999972</td>\n",
       "      <td>0.16121013599053424</td>\n",
       "      <td>2.1088900000000035e-05</td>\n",
       "      <td>0.03225879191744855</td>\n",
       "      <td>0.7634951</td>\n",
       "      <td>0.19964847471308333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162531</th>\n",
       "      <td>-0.004739137999999999</td>\n",
       "      <td>0.18341791502114752</td>\n",
       "      <td>0.01831918</td>\n",
       "      <td>-0.08421640261440295</td>\n",
       "      <td>0.8631911000000001</td>\n",
       "      <td>-0.13082919282190275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162532</th>\n",
       "      <td>0.01537472963181818</td>\n",
       "      <td>0.19991156372718366</td>\n",
       "      <td>0.029377065</td>\n",
       "      <td>-0.3065872880169196</td>\n",
       "      <td>0.8825871000000001</td>\n",
       "      <td>0.2778884633239045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162533 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean_S1                std_S1               median_S1  \\\n",
       "0              -0.000414370442  0.043120406327645536            -0.003243883   \n",
       "1               -0.00149953008   0.08873689907904413  -0.0073719135000000005   \n",
       "2        -0.002099744577200001   0.12369873116059492             -0.01570684   \n",
       "3       -0.0033677626000000005    0.1388221230414223            -0.042125805   \n",
       "4        0.0033172219000000003   0.13300805870201626           -0.0047542875   \n",
       "...                        ...                   ...                     ...   \n",
       "162528    0.014895218723999999    0.1436816838486326           -0.0041809065   \n",
       "162529    0.014240604980000002   0.13816677091787724            0.0084757445   \n",
       "162530  -0.0018931615239999972   0.16121013599053424  2.1088900000000035e-05   \n",
       "162531   -0.004739137999999999   0.18341791502114752              0.01831918   \n",
       "162532     0.01537472963181818   0.19991156372718366             0.029377065   \n",
       "\n",
       "                      skew_S1      amp_max_min_S1           kurtosis_S1  \\\n",
       "0        -0.41442675239991716          0.18522184   0.18229650179968981   \n",
       "1       -0.008557772829157796           0.3630676   -0.6650972729370102   \n",
       "2           0.588571492652289  0.6131021999999999    0.7530364721892133   \n",
       "3         0.26839345162009703           0.5585321   -0.7062843969531509   \n",
       "4          0.3868517885124701  0.5399411000000001  -0.14875481556053805   \n",
       "...                       ...                 ...                   ...   \n",
       "162528       1.12900580926754           0.8092328    3.0430900402674945   \n",
       "162529  -0.042066688930058285  0.6926772000000001    0.1608569660924406   \n",
       "162530    0.03225879191744855           0.7634951   0.19964847471308333   \n",
       "162531   -0.08421640261440295  0.8631911000000001  -0.13082919282190275   \n",
       "162532    -0.3065872880169196  0.8825871000000001    0.2778884633239045   \n",
       "\n",
       "        damaged  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "162528        0  \n",
       "162529        0  \n",
       "162530        0  \n",
       "162531        0  \n",
       "162532        0  \n",
       "\n",
       "[162533 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defs_.createDatabaseSingleSensor(df_final, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario is: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6204f69bc9ac4a5a8f5b80141117160a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'rf_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22608\\160740823.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_scenario_S1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_scenario_S1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_scenario_S1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mrf_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrf_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sensor'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rf_model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_models' is not defined"
     ]
    }
   ],
   "source": [
    "# sensored = rf_models.loc[rf_models['Sensor'] == 20, 'rf_model']\n",
    "\n",
    "path_used = path[0]\n",
    "df_scenario = defs_.createDatabase(path_used);\n",
    "df_scenario = df_scenario.astype(float);\n",
    "scenario = defs_.getDamageScenarioLabel(path_used);\n",
    "print('Scenario is: ' + str(scenario))\n",
    "\n",
    "listing = {};\n",
    "\n",
    "for i in tqdm(range(30)) :\n",
    "    sensor = i+1;\n",
    "    sensor_label = 'S'+ str(sensor);\n",
    "    df_scenario_S1 = defs_.getStatisticalCaracteristics(df_scenario,sensor_label);\n",
    "    df_scenario_S1 = df_scenario_S1.astype(float)\n",
    "\n",
    "    std_scaler = StandardScaler();\n",
    "    X_scaled = pd.DataFrame(std_scaler.fit_transform(df_scenario_S1), columns=df_scenario_S1.columns, index=df_scenario_S1.index);\n",
    "\n",
    "    rf_ = rf_models.loc[rf_models['Sensor'] == sensor, 'rf_model'];\n",
    "\n",
    "    y_pred = rf_[0].predict(X_scaled);\n",
    "    listing[sensor_label] = defs_.probabilityOfDamage(y_pred)\n",
    "\n",
    "listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_S1</th>\n",
       "      <th>std_S1</th>\n",
       "      <th>median_S1</th>\n",
       "      <th>skew_S1</th>\n",
       "      <th>amp_max_min_S1</th>\n",
       "      <th>kurtosis_S1</th>\n",
       "      <th>mean_S2</th>\n",
       "      <th>std_S2</th>\n",
       "      <th>median_S2</th>\n",
       "      <th>...</th>\n",
       "      <th>skew_S29</th>\n",
       "      <th>amp_max_min_S29</th>\n",
       "      <th>kurtosis_S29</th>\n",
       "      <th>mean_S30</th>\n",
       "      <th>std_S30</th>\n",
       "      <th>median_S30</th>\n",
       "      <th>skew_S30</th>\n",
       "      <th>amp_max_min_S30</th>\n",
       "      <th>kurtosis_S30</th>\n",
       "      <th>Scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000414370442</td>\n",
       "      <td>0.043120406327645536</td>\n",
       "      <td>-0.003243883</td>\n",
       "      <td>-0.41442675239991716</td>\n",
       "      <td>0.18522184</td>\n",
       "      <td>0.18229650179968981</td>\n",
       "      <td>0.002539496899999999</td>\n",
       "      <td>0.07326709498315241</td>\n",
       "      <td>-0.0030380579999999997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02354757068943298</td>\n",
       "      <td>0.20867329</td>\n",
       "      <td>-0.09261218246012026</td>\n",
       "      <td>0.0026082206780000004</td>\n",
       "      <td>0.05630144437603952</td>\n",
       "      <td>0.0013889112500000001</td>\n",
       "      <td>-0.0270176906355013</td>\n",
       "      <td>0.2728724</td>\n",
       "      <td>0.5556625881783335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.00149953008</td>\n",
       "      <td>0.08873689907904413</td>\n",
       "      <td>-0.0073719135000000005</td>\n",
       "      <td>-0.008557772829157796</td>\n",
       "      <td>0.3630676</td>\n",
       "      <td>-0.6650972729370102</td>\n",
       "      <td>0.00025711601200000044</td>\n",
       "      <td>0.07111379813647783</td>\n",
       "      <td>0.0032996125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.33598191878862077</td>\n",
       "      <td>0.34748330000000005</td>\n",
       "      <td>0.013995772218858171</td>\n",
       "      <td>-0.003290065054</td>\n",
       "      <td>0.0653112391699274</td>\n",
       "      <td>0.0015525472000000001</td>\n",
       "      <td>-0.3633085961641189</td>\n",
       "      <td>0.25344679999999997</td>\n",
       "      <td>-0.6949649764837647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.002099744577200001</td>\n",
       "      <td>0.12369873116059492</td>\n",
       "      <td>-0.01570684</td>\n",
       "      <td>0.588571492652289</td>\n",
       "      <td>0.6131021999999999</td>\n",
       "      <td>0.7530364721892133</td>\n",
       "      <td>-0.0053900647</td>\n",
       "      <td>0.14869303266240297</td>\n",
       "      <td>-0.0086230175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.417049573113767</td>\n",
       "      <td>0.4983139</td>\n",
       "      <td>-0.38685487627178805</td>\n",
       "      <td>0.002435254539999999</td>\n",
       "      <td>0.12316842935483063</td>\n",
       "      <td>0.0095598715</td>\n",
       "      <td>-0.20858393789052662</td>\n",
       "      <td>0.50685</td>\n",
       "      <td>-0.6315823705462122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.0033677626000000005</td>\n",
       "      <td>0.1388221230414223</td>\n",
       "      <td>-0.042125805</td>\n",
       "      <td>0.26839345162009703</td>\n",
       "      <td>0.5585321</td>\n",
       "      <td>-0.7062843969531509</td>\n",
       "      <td>0.0016413805600000008</td>\n",
       "      <td>0.11507735752260885</td>\n",
       "      <td>0.003905859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06925917396814457</td>\n",
       "      <td>0.681977</td>\n",
       "      <td>0.018615043190842062</td>\n",
       "      <td>-0.005249770819999999</td>\n",
       "      <td>0.11419204169476571</td>\n",
       "      <td>0.0048140744999999995</td>\n",
       "      <td>0.06931212580263177</td>\n",
       "      <td>0.5114897</td>\n",
       "      <td>-0.5375619884710399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0033172219000000003</td>\n",
       "      <td>0.13300805870201626</td>\n",
       "      <td>-0.0047542875</td>\n",
       "      <td>0.3868517885124701</td>\n",
       "      <td>0.5399411000000001</td>\n",
       "      <td>-0.14875481556053805</td>\n",
       "      <td>0.004867889820000002</td>\n",
       "      <td>0.16221732911934414</td>\n",
       "      <td>0.027308365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32182510708430795</td>\n",
       "      <td>0.530455</td>\n",
       "      <td>-0.5500877540563107</td>\n",
       "      <td>-1.9895200000000397e-06</td>\n",
       "      <td>0.11270303133598643</td>\n",
       "      <td>-0.0029228609999999997</td>\n",
       "      <td>0.5809104505583018</td>\n",
       "      <td>0.5124597</td>\n",
       "      <td>0.70313499094634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162528</th>\n",
       "      <td>162528</td>\n",
       "      <td>0.014895218723999999</td>\n",
       "      <td>0.1436816838486326</td>\n",
       "      <td>-0.0041809065</td>\n",
       "      <td>1.12900580926754</td>\n",
       "      <td>0.8092328</td>\n",
       "      <td>3.0430900402674945</td>\n",
       "      <td>0.005905574820200001</td>\n",
       "      <td>0.12153671923777914</td>\n",
       "      <td>3.9536505e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.07322779606086158</td>\n",
       "      <td>0.5400841000000001</td>\n",
       "      <td>-0.42105004936897306</td>\n",
       "      <td>0.0065484234279999986</td>\n",
       "      <td>0.10981191370481382</td>\n",
       "      <td>0.026138124999999998</td>\n",
       "      <td>-0.5863665072579036</td>\n",
       "      <td>0.4496974</td>\n",
       "      <td>-0.20020082177117304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162529</th>\n",
       "      <td>162529</td>\n",
       "      <td>0.014240604980000002</td>\n",
       "      <td>0.13816677091787724</td>\n",
       "      <td>0.0084757445</td>\n",
       "      <td>-0.042066688930058285</td>\n",
       "      <td>0.6926772000000001</td>\n",
       "      <td>0.1608569660924406</td>\n",
       "      <td>0.010850616999999998</td>\n",
       "      <td>0.1367264908983254</td>\n",
       "      <td>0.040029999999999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3525890771414916</td>\n",
       "      <td>0.7216627</td>\n",
       "      <td>1.1391818207869386</td>\n",
       "      <td>0.0032942288200000004</td>\n",
       "      <td>0.16266539283127435</td>\n",
       "      <td>0.0002579104999999998</td>\n",
       "      <td>0.12494271506529496</td>\n",
       "      <td>0.67206</td>\n",
       "      <td>-0.7725851436083033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162530</th>\n",
       "      <td>162530</td>\n",
       "      <td>-0.0018931615239999972</td>\n",
       "      <td>0.16121013599053424</td>\n",
       "      <td>2.1088900000000035e-05</td>\n",
       "      <td>0.03225879191744855</td>\n",
       "      <td>0.7634951</td>\n",
       "      <td>0.19964847471308333</td>\n",
       "      <td>0.0035580945799999998</td>\n",
       "      <td>0.13752647299896875</td>\n",
       "      <td>0.0064928979999999996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2598417655695789</td>\n",
       "      <td>0.6364637</td>\n",
       "      <td>-0.5843366819730242</td>\n",
       "      <td>-0.00022290461999999845</td>\n",
       "      <td>0.17004421492624752</td>\n",
       "      <td>-0.0046039345</td>\n",
       "      <td>0.04561572618057951</td>\n",
       "      <td>0.6937398</td>\n",
       "      <td>-0.6636288784607522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162531</th>\n",
       "      <td>162531</td>\n",
       "      <td>-0.004739137999999999</td>\n",
       "      <td>0.18341791502114752</td>\n",
       "      <td>0.01831918</td>\n",
       "      <td>-0.08421640261440295</td>\n",
       "      <td>0.8631911000000001</td>\n",
       "      <td>-0.13082919282190275</td>\n",
       "      <td>-0.00969176552</td>\n",
       "      <td>0.15705896655829976</td>\n",
       "      <td>-0.0031893155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013559759978589134</td>\n",
       "      <td>0.6566634</td>\n",
       "      <td>-0.09818481373975851</td>\n",
       "      <td>0.0014228850600000004</td>\n",
       "      <td>0.12784962043644352</td>\n",
       "      <td>-0.007478978</td>\n",
       "      <td>0.12382761824959346</td>\n",
       "      <td>0.53823</td>\n",
       "      <td>-0.23521563162570214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162532</th>\n",
       "      <td>162532</td>\n",
       "      <td>0.01537472963181818</td>\n",
       "      <td>0.19991156372718366</td>\n",
       "      <td>0.029377065</td>\n",
       "      <td>-0.3065872880169196</td>\n",
       "      <td>0.8825871000000001</td>\n",
       "      <td>0.2778884633239045</td>\n",
       "      <td>-0.0005120824204545468</td>\n",
       "      <td>0.13599107750418757</td>\n",
       "      <td>-0.020208135000000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281496799819192</td>\n",
       "      <td>0.6352335</td>\n",
       "      <td>-0.4742778235837064</td>\n",
       "      <td>-0.003548396159090909</td>\n",
       "      <td>0.11867825790219544</td>\n",
       "      <td>-0.012866782</td>\n",
       "      <td>0.08207761054673468</td>\n",
       "      <td>0.5852146</td>\n",
       "      <td>0.00903453657147324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162533 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                 mean_S1                std_S1  \\\n",
       "0               0         -0.000414370442  0.043120406327645536   \n",
       "1               1          -0.00149953008   0.08873689907904413   \n",
       "2               2   -0.002099744577200001   0.12369873116059492   \n",
       "3               3  -0.0033677626000000005    0.1388221230414223   \n",
       "4               4   0.0033172219000000003   0.13300805870201626   \n",
       "...           ...                     ...                   ...   \n",
       "162528     162528    0.014895218723999999    0.1436816838486326   \n",
       "162529     162529    0.014240604980000002   0.13816677091787724   \n",
       "162530     162530  -0.0018931615239999972   0.16121013599053424   \n",
       "162531     162531   -0.004739137999999999   0.18341791502114752   \n",
       "162532     162532     0.01537472963181818   0.19991156372718366   \n",
       "\n",
       "                     median_S1                skew_S1      amp_max_min_S1  \\\n",
       "0                 -0.003243883   -0.41442675239991716          0.18522184   \n",
       "1       -0.0073719135000000005  -0.008557772829157796           0.3630676   \n",
       "2                  -0.01570684      0.588571492652289  0.6131021999999999   \n",
       "3                 -0.042125805    0.26839345162009703           0.5585321   \n",
       "4                -0.0047542875     0.3868517885124701  0.5399411000000001   \n",
       "...                        ...                    ...                 ...   \n",
       "162528           -0.0041809065       1.12900580926754           0.8092328   \n",
       "162529            0.0084757445  -0.042066688930058285  0.6926772000000001   \n",
       "162530  2.1088900000000035e-05    0.03225879191744855           0.7634951   \n",
       "162531              0.01831918   -0.08421640261440295  0.8631911000000001   \n",
       "162532             0.029377065    -0.3065872880169196  0.8825871000000001   \n",
       "\n",
       "                 kurtosis_S1                 mean_S2               std_S2  \\\n",
       "0        0.18229650179968981    0.002539496899999999  0.07326709498315241   \n",
       "1        -0.6650972729370102  0.00025711601200000044  0.07111379813647783   \n",
       "2         0.7530364721892133           -0.0053900647  0.14869303266240297   \n",
       "3        -0.7062843969531509   0.0016413805600000008  0.11507735752260885   \n",
       "4       -0.14875481556053805    0.004867889820000002  0.16221732911934414   \n",
       "...                      ...                     ...                  ...   \n",
       "162528    3.0430900402674945    0.005905574820200001  0.12153671923777914   \n",
       "162529    0.1608569660924406    0.010850616999999998   0.1367264908983254   \n",
       "162530   0.19964847471308333   0.0035580945799999998  0.13752647299896875   \n",
       "162531  -0.13082919282190275          -0.00969176552  0.15705896655829976   \n",
       "162532    0.2778884633239045  -0.0005120824204545468  0.13599107750418757   \n",
       "\n",
       "                     median_S2  ...              skew_S29  \\\n",
       "0       -0.0030380579999999997  ...  -0.02354757068943298   \n",
       "1                 0.0032996125  ...  -0.33598191878862077   \n",
       "2                -0.0086230175  ...    -0.417049573113767   \n",
       "3                  0.003905859  ...   0.06925917396814457   \n",
       "4                  0.027308365  ...   0.32182510708430795   \n",
       "...                        ...  ...                   ...   \n",
       "162528           3.9536505e-05  ...  -0.07322779606086158   \n",
       "162529    0.040029999999999996  ...    0.3525890771414916   \n",
       "162530   0.0064928979999999996  ...   -0.2598417655695789   \n",
       "162531           -0.0031893155  ...  0.013559759978589134   \n",
       "162532   -0.020208135000000002  ...     0.281496799819192   \n",
       "\n",
       "            amp_max_min_S29          kurtosis_S29                 mean_S30  \\\n",
       "0                0.20867329  -0.09261218246012026    0.0026082206780000004   \n",
       "1       0.34748330000000005  0.013995772218858171          -0.003290065054   \n",
       "2                 0.4983139  -0.38685487627178805     0.002435254539999999   \n",
       "3                  0.681977  0.018615043190842062    -0.005249770819999999   \n",
       "4                  0.530455   -0.5500877540563107  -1.9895200000000397e-06   \n",
       "...                     ...                   ...                      ...   \n",
       "162528   0.5400841000000001  -0.42105004936897306    0.0065484234279999986   \n",
       "162529            0.7216627    1.1391818207869386    0.0032942288200000004   \n",
       "162530            0.6364637   -0.5843366819730242  -0.00022290461999999845   \n",
       "162531            0.6566634  -0.09818481373975851    0.0014228850600000004   \n",
       "162532            0.6352335   -0.4742778235837064    -0.003548396159090909   \n",
       "\n",
       "                    std_S30              median_S30              skew_S30  \\\n",
       "0       0.05630144437603952   0.0013889112500000001   -0.0270176906355013   \n",
       "1        0.0653112391699274   0.0015525472000000001   -0.3633085961641189   \n",
       "2       0.12316842935483063            0.0095598715  -0.20858393789052662   \n",
       "3       0.11419204169476571   0.0048140744999999995   0.06931212580263177   \n",
       "4       0.11270303133598643  -0.0029228609999999997    0.5809104505583018   \n",
       "...                     ...                     ...                   ...   \n",
       "162528  0.10981191370481382    0.026138124999999998   -0.5863665072579036   \n",
       "162529  0.16266539283127435   0.0002579104999999998   0.12494271506529496   \n",
       "162530  0.17004421492624752           -0.0046039345   0.04561572618057951   \n",
       "162531  0.12784962043644352            -0.007478978   0.12382761824959346   \n",
       "162532  0.11867825790219544            -0.012866782   0.08207761054673468   \n",
       "\n",
       "            amp_max_min_S30          kurtosis_S30 Scenario  \n",
       "0                 0.2728724    0.5556625881783335        1  \n",
       "1       0.25344679999999997   -0.6949649764837647        1  \n",
       "2                   0.50685   -0.6315823705462122        1  \n",
       "3                 0.5114897   -0.5375619884710399        1  \n",
       "4                 0.5124597      0.70313499094634        1  \n",
       "...                     ...                   ...      ...  \n",
       "162528            0.4496974  -0.20020082177117304        0  \n",
       "162529              0.67206   -0.7725851436083033        0  \n",
       "162530            0.6937398   -0.6636288784607522        0  \n",
       "162531              0.53823  -0.23521563162570214        0  \n",
       "162532            0.5852146   0.00903453657147324        0  \n",
       "\n",
       "[162533 rows x 182 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_S1</th>\n",
       "      <th>std_S1</th>\n",
       "      <th>median_S1</th>\n",
       "      <th>skew_S1</th>\n",
       "      <th>amp_max_min_S1</th>\n",
       "      <th>kurtosis_S1</th>\n",
       "      <th>damaged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000414370442</td>\n",
       "      <td>0.043120406327645536</td>\n",
       "      <td>-0.003243883</td>\n",
       "      <td>-0.41442675239991716</td>\n",
       "      <td>0.18522184</td>\n",
       "      <td>0.18229650179968981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.00149953008</td>\n",
       "      <td>0.08873689907904413</td>\n",
       "      <td>-0.0073719135000000005</td>\n",
       "      <td>-0.008557772829157796</td>\n",
       "      <td>0.3630676</td>\n",
       "      <td>-0.6650972729370102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002099744577200001</td>\n",
       "      <td>0.12369873116059492</td>\n",
       "      <td>-0.01570684</td>\n",
       "      <td>0.588571492652289</td>\n",
       "      <td>0.6131021999999999</td>\n",
       "      <td>0.7530364721892133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0033677626000000005</td>\n",
       "      <td>0.1388221230414223</td>\n",
       "      <td>-0.042125805</td>\n",
       "      <td>0.26839345162009703</td>\n",
       "      <td>0.5585321</td>\n",
       "      <td>-0.7062843969531509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0033172219000000003</td>\n",
       "      <td>0.13300805870201626</td>\n",
       "      <td>-0.0047542875</td>\n",
       "      <td>0.3868517885124701</td>\n",
       "      <td>0.5399411000000001</td>\n",
       "      <td>-0.14875481556053805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162528</th>\n",
       "      <td>0.014895218723999999</td>\n",
       "      <td>0.1436816838486326</td>\n",
       "      <td>-0.0041809065</td>\n",
       "      <td>1.12900580926754</td>\n",
       "      <td>0.8092328</td>\n",
       "      <td>3.0430900402674945</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162529</th>\n",
       "      <td>0.014240604980000002</td>\n",
       "      <td>0.13816677091787724</td>\n",
       "      <td>0.0084757445</td>\n",
       "      <td>-0.042066688930058285</td>\n",
       "      <td>0.6926772000000001</td>\n",
       "      <td>0.1608569660924406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162530</th>\n",
       "      <td>-0.0018931615239999972</td>\n",
       "      <td>0.16121013599053424</td>\n",
       "      <td>2.1088900000000035e-05</td>\n",
       "      <td>0.03225879191744855</td>\n",
       "      <td>0.7634951</td>\n",
       "      <td>0.19964847471308333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162531</th>\n",
       "      <td>-0.004739137999999999</td>\n",
       "      <td>0.18341791502114752</td>\n",
       "      <td>0.01831918</td>\n",
       "      <td>-0.08421640261440295</td>\n",
       "      <td>0.8631911000000001</td>\n",
       "      <td>-0.13082919282190275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162532</th>\n",
       "      <td>0.01537472963181818</td>\n",
       "      <td>0.19991156372718366</td>\n",
       "      <td>0.029377065</td>\n",
       "      <td>-0.3065872880169196</td>\n",
       "      <td>0.8825871000000001</td>\n",
       "      <td>0.2778884633239045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162533 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean_S1                std_S1               median_S1  \\\n",
       "0              -0.000414370442  0.043120406327645536            -0.003243883   \n",
       "1               -0.00149953008   0.08873689907904413  -0.0073719135000000005   \n",
       "2        -0.002099744577200001   0.12369873116059492             -0.01570684   \n",
       "3       -0.0033677626000000005    0.1388221230414223            -0.042125805   \n",
       "4        0.0033172219000000003   0.13300805870201626           -0.0047542875   \n",
       "...                        ...                   ...                     ...   \n",
       "162528    0.014895218723999999    0.1436816838486326           -0.0041809065   \n",
       "162529    0.014240604980000002   0.13816677091787724            0.0084757445   \n",
       "162530  -0.0018931615239999972   0.16121013599053424  2.1088900000000035e-05   \n",
       "162531   -0.004739137999999999   0.18341791502114752              0.01831918   \n",
       "162532     0.01537472963181818   0.19991156372718366             0.029377065   \n",
       "\n",
       "                      skew_S1      amp_max_min_S1           kurtosis_S1  \\\n",
       "0        -0.41442675239991716          0.18522184   0.18229650179968981   \n",
       "1       -0.008557772829157796           0.3630676   -0.6650972729370102   \n",
       "2           0.588571492652289  0.6131021999999999    0.7530364721892133   \n",
       "3         0.26839345162009703           0.5585321   -0.7062843969531509   \n",
       "4          0.3868517885124701  0.5399411000000001  -0.14875481556053805   \n",
       "...                       ...                 ...                   ...   \n",
       "162528       1.12900580926754           0.8092328    3.0430900402674945   \n",
       "162529  -0.042066688930058285  0.6926772000000001    0.1608569660924406   \n",
       "162530    0.03225879191744855           0.7634951   0.19964847471308333   \n",
       "162531   -0.08421640261440295  0.8631911000000001  -0.13082919282190275   \n",
       "162532    -0.3065872880169196  0.8825871000000001    0.2778884633239045   \n",
       "\n",
       "        damaged  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "162528        0  \n",
       "162529        0  \n",
       "162530        0  \n",
       "162531        0  \n",
       "162532        0  \n",
       "\n",
       "[162533 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = defs_.createDatabaseSingleSensor(df_final, 1)\n",
    "\n",
    "df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
