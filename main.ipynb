{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy.fft import fft, ifft\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "#IMPORTING FUNCTIONS FOR CLASSIFIERS\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedShuffleSplit, TimeSeriesSplit, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "#IMPORTING FUNCTIONS FROM ./defs\n",
    "\n",
    "from defs import defs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATHS USED\n",
    "path_quick_test = [\n",
    "    \"./database_raw/DatasetA/zzzAD1.txt\",\n",
    "    \"./database_raw/DatasetA/zzzAD30.txt\",\n",
    "    \"./database_raw/DatasetA/zzzAD12.txt\",\n",
    "]\n",
    "\n",
    "path = glob.glob(\"./database_raw/DatasetA/zzzA*.txt\", recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create pratical database with three different scenarios available on DATASETA, use to test code before apply on full database in order to save time\n",
    "df_final = defs_.prepareDatabase(path);\n",
    "### Instead of creating database every time, it was exported as a csv file named 'dataframesimples' on root of project, imported using following code\n",
    "#######\n",
    "#######\n",
    "df_final.to_csv('dataframe_final')\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate DF's \n",
    "\n",
    "## Create full database with all data available on DATASETA\n",
    "# df_final = defs_.prepareDatabase(path);\n",
    "### Instead of creating database every time, it was exported as a csv file named 'dataframe_final' on root of project, imported using following code\n",
    "#######\n",
    "df_final = pd.read_csv('dataframe_final', dtype='unicode');\n",
    "#######\n",
    "\n",
    "## Create pratical database with three different scenarios available on DATASETA, use to test code before apply on full database in order to save time\n",
    "# df_quick_test = defs_.prepareDatabase(path_quick_test);\n",
    "### Instead of creating database every time, it was exported as a csv file named 'dataframesimples' on root of project, imported using following code\n",
    "#######\n",
    "df_quick_test = pd.read_csv('dataframe_simples', dtype='unicode');\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start random forest Model\n",
    "\n",
    "df_rf = df_quick_test\n",
    "\n",
    "# Setting target variable\n",
    "y = df_rf['Scenario']\n",
    "\n",
    "# Setting other variables\n",
    "X = df_rf.drop(columns=['Scenario'])\n",
    "# X = X.drop(columns=['Sensor'])\n",
    "\n",
    "# encoder = LabelBinarizer()\n",
    "# X_lb = encoder.fit_transform(X['Sensor'])\n",
    "# Sensor = X['Sensor']\n",
    "X\n",
    "X_new = pd.concat([X.loc[X['Sensor'].eq('S1').index],X.loc[X['Sensor'].eq('S2').index]],axis=1)\n",
    "X_new = X_new.drop(columns=['Sensor'])\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(X['Sensor'])\n",
    "X['Sensor_encoded'] = le.transform(X['Sensor'])\n",
    "\n",
    "X = X.drop(columns=['Sensor'])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, shuffle=False) \n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "X_scaled_train = pd.DataFrame(std_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_scaled_test = pd.DataFrame(std_scaler.transform(X_test),columns=X_train.columns,index=X_test.index)\n",
    "\n",
    "X_scaled_train,X_scaled_test, y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rf.fit(X_scaled_train,y_train)\n",
    "y_pred = rf.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "et.fit(X_scaled_train,y_train)\n",
    "y_pred = rf.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
